{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/dfki-artificial-3000-unsupervised-ad.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nOutlier label distribution:\")\n",
    "print(df['outlier_label'].value_counts())\n",
    "\n",
    "# Convert outlier_label to binary for plotting\n",
    "df['is_outlier'] = (df['outlier_label'] == 'outlier').astype(int)\n",
    "\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot normal points\n",
    "normal_mask = df['is_outlier'] == 0\n",
    "ax.scatter(df.loc[normal_mask, 'attribute_1'], \n",
    "           df.loc[normal_mask, 'attribute_2'],\n",
    "           c='blue', alpha=0.5, s=20, label='Normal')\n",
    "\n",
    "# Plot outliers\n",
    "outlier_mask = df['is_outlier'] == 1\n",
    "ax.scatter(df.loc[outlier_mask, 'attribute_1'], \n",
    "           df.loc[outlier_mask, 'attribute_2'],\n",
    "           c='red', alpha=0.7, s=30, label='Outlier', marker='x')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title('DFKI Artificial Dataset (3000 samples)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(df[['attribute_1', 'attribute_2']].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df[['attribute_1', 'attribute_2']].values\n",
    "y = df['is_outlier'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "k = 20\n",
    "knn_detector = KNN(n_neighbors=k, contamination=0.01)\n",
    "knn_detector.fit(X_normalized)\n",
    "\n",
    "scores = knn_detector.decision_scores_\n",
    "\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "ranks = np.empty_like(scores, dtype=int)\n",
    "ranks[sorted_indices] = np.arange(1, len(scores) + 1)\n",
    "\n",
    "df['knn_score'] = scores\n",
    "df['knn_rank'] = ranks\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=scores, cmap='viridis', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title(f'Points colored by k-NN Score (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=ranks, cmap='plasma_r', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title(f'Points colored by k-NN Rank', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "cbar2.set_label('Rank (1 = most anomalous)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df[['attribute_1', 'attribute_2']].values\n",
    "y = df['is_outlier'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "k = 20\n",
    "lof_detector = LOF(n_neighbors=k, contamination=0.01)\n",
    "lof_detector.fit(X_normalized)\n",
    "\n",
    "scores = lof_detector.decision_scores_\n",
    "\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "ranks = np.empty_like(scores, dtype=int)\n",
    "ranks[sorted_indices] = np.arange(1, len(scores) + 1)\n",
    "\n",
    "df['lof_score'] = scores\n",
    "df['lof_rank'] = ranks\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=scores, cmap='viridis', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title(f'Points colored by LOF Score (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=ranks, cmap='plasma_r', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title(f'Points colored by LOF Rank', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "cbar2.set_label('Rank (1 = most anomalous)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean combination of k-NN and LOF scores: magnitude + angle\n",
    "\n",
    "knn_scores = df['knn_score'].values\n",
    "lof_scores = df['lof_score'].values\n",
    "\n",
    "mag = np.sqrt(knn_scores**2 + lof_scores**2)\n",
    "angle = np.arctan2(lof_scores, knn_scores)  # LOF vs k-NN\n",
    "\n",
    "# Store for later use if needed\n",
    "df['euc_mag'] = mag\n",
    "df['euc_angle'] = angle\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: magnitude of combined anomaly signal\n",
    "ax1 = axes[0]\n",
    "sc1 = ax1.scatter(\n",
    "    df['attribute_1'], df['attribute_2'],\n",
    "    c=mag, cmap='viridis',\n",
    "    s=30, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    ")\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title('Outlier magnitude: sqrt(LOF^2 + kNN^2)', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(sc1, ax=ax1)\n",
    "cbar1.set_label('Magnitude', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: angle indicating locality vs globality\n",
    "ax2 = axes[1]\n",
    "sc2 = ax2.scatter(\n",
    "    df['attribute_1'], df['attribute_2'],\n",
    "    c=angle, cmap='twilight_shifted',\n",
    "    s=30, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    ")\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title('Locality vs Globality: angle = arctan2(LOF, kNN)', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(sc2, ax=ax2)\n",
    "cbar2.set_label('Angle (radians)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 0\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + p) / (knn_rank + p)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmax = 1\n",
    "vmin = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 20\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + p) / (knn_rank + p)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmax = 1\n",
    "vmin = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"k-NN mean score by label:\")\n",
    "print(df.groupby('is_outlier')['knn_score'].mean())\n",
    "print(\"LOF mean score by label:\")\n",
    "print(df.groupby('is_outlier')['lof_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def analyze_ensemble_globality(df, X_normalized, k_list=[3, 4, 5, 6, 7], contamination=0.05):\n",
    "    \"\"\"\n",
    "    Computes Globality Index by averaging distances to centroids over multiple k values.\n",
    "    Filters top anomalies using existing LOF scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Running Ensemble Globality Analysis ---\")\n",
    "    print(f\"Averaging cluster structures for k = {k_list}\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. ENSEMBLE DISTANCE CALCULATION\n",
    "    # ==========================================\n",
    "    n_samples = X_normalized.shape[0]\n",
    "    cumulative_dists = np.zeros(n_samples)\n",
    "    \n",
    "    # Iterate through each k in the list\n",
    "    for k in k_list:\n",
    "        # Fit KMeans\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto').fit(X_normalized)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Get min distance to ANY center for this specific k\n",
    "        dists = pairwise_distances(X_normalized, centers).min(axis=1)\n",
    "        \n",
    "        # Add to cumulative sum\n",
    "        cumulative_dists += dists\n",
    "\n",
    "    # Average the distances\n",
    "    avg_dists_to_centers = cumulative_dists / len(k_list)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 2. FILTER CANDIDATES (Top C% by LOF)\n",
    "    # ==========================================\n",
    "    # We assume 'lof_score' already exists in df from previous steps\n",
    "    if 'lof_score' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'lof_score' column.\")\n",
    "        \n",
    "    threshold = df['lof_score'].quantile(1 - contamination)\n",
    "    candidate_mask = df['lof_score'] > threshold\n",
    "    \n",
    "    # Extract distances only for the candidates\n",
    "    candidate_dists = avg_dists_to_centers[candidate_mask]\n",
    "    candidate_indices = df.index[candidate_mask]\n",
    "    \n",
    "    # ==========================================\n",
    "    # 3. COMPUTE FINAL INDEX (Standardize Subset)\n",
    "    # ==========================================\n",
    "    # Normalize the average distances of the candidates to 0-1 for coloring\n",
    "    scaler_subset = MinMaxScaler()\n",
    "    globality_index = scaler_subset.fit_transform(candidate_dists.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Store in DF\n",
    "    col_name = 'ensemble_globality_index'\n",
    "    df[col_name] = np.nan\n",
    "    df.loc[candidate_indices, col_name] = globality_index\n",
    "    \n",
    "    # ==========================================\n",
    "    # 4. VISUALIZATION\n",
    "    # ==========================================\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # A. Plot Background (Normal Points)\n",
    "    ax.scatter(df.loc[~candidate_mask, 'attribute_1'], \n",
    "               df.loc[~candidate_mask, 'attribute_2'],\n",
    "               c='gainsboro', s=20, alpha=0.4, label='Normal Data')\n",
    "\n",
    "    # B. Plot Candidates (Colored by Ensemble Globality)\n",
    "    scatter = ax.scatter(df.loc[candidate_mask, 'attribute_1'], \n",
    "                         df.loc[candidate_mask, 'attribute_2'], \n",
    "                         c=globality_index, \n",
    "                         cmap='plasma', # plasma is great for intensity\n",
    "                         s=60, alpha=0.9, edgecolors='black', linewidth=0.5,\n",
    "                         label=f'Top {int(contamination*100)}% Anomalies')\n",
    "\n",
    "    # Formatting\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(f'Ensemble Globality (Avg Dist to Centers, k={k_list})', fontsize=11)\n",
    "    cbar.set_ticks([0, 0.5, 1])\n",
    "    cbar.set_ticklabels(['Local (Sparse Inlier)', 'Mixed', 'Global (Isolated)'])\n",
    "\n",
    "    ax.set_title(f'Ensemble Globality Map (Averaged over k={k_list})\\n'\n",
    "                 f'Showing top {int(contamination*100)}% LOF candidates', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Attribute 1')\n",
    "    ax.set_ylabel('Attribute 2')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# HOW TO RUN IT\n",
    "# ==========================================\n",
    "\n",
    "# We average over k=3, 4, 5, 6, 7 to account for structural ambiguity\n",
    "# This makes the \"Global\" score much more scientifically robust\n",
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[5], \n",
    "    contamination=0.05\n",
    ")\n",
    "\n",
    "# Check the top results\n",
    "print(\"\\nTop 5 Global Outliers (Most Isolated across all k):\")\n",
    "cols = ['attribute_1', 'attribute_2', 'ensemble_globality_index']\n",
    "print(df.dropna(subset=['ensemble_globality_index']).nlargest(5, 'ensemble_globality_index')[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[3, 4, 5, 6, 7], \n",
    "    contamination=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[4,5,6,7,8,9,10], \n",
    "    contamination=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[3,4,5,6,7], \n",
    "    contamination=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 20\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + knn_rank) / 2* (lof_rank)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmin = ratio_min\n",
    "vmax = ratio_max\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Majority Voting Algorithm for Local vs Global Outlier Classification\n",
    "\n",
    "**Key Idea:**\n",
    "- If a point is in the top-c anomalies for **both k-NN and LOF** → vote for **Global**\n",
    "- If a point is in the top-c anomalies for **LOF only** (not k-NN) → vote for **Local**\n",
    "- Repeat for multiple c thresholds and use **majority voting** to classify each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_classifier(df, c_values, knn_rank_col='knn_rank', lof_rank_col='lof_rank'):\n",
    "    \"\"\"\n",
    "    Classify anomalies as local or global using majority voting across multiple thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame containing k-NN and LOF ranks\n",
    "    c_values : list or array\n",
    "        List of top-c thresholds to test (e.g., [10, 20, 30, 40, 50, 100])\n",
    "    knn_rank_col : str\n",
    "        Column name for k-NN ranks\n",
    "    lof_rank_col : str\n",
    "        Column name for LOF ranks\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added columns:\n",
    "        - 'votes_global': number of global votes\n",
    "        - 'votes_local': number of local votes\n",
    "        - 'classification': 'global', 'local', or 'normal' (no votes)\n",
    "        - 'confidence': vote margin (higher = more confident)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize vote counters for each point\n",
    "    votes_global = np.zeros(len(df), dtype=int)\n",
    "    votes_local = np.zeros(len(df), dtype=int)\n",
    "    \n",
    "    # For each threshold c\n",
    "    for c in c_values:\n",
    "        # Get top c points by k-NN rank\n",
    "        top_knn = set(df.nsmallest(c, knn_rank_col).index)\n",
    "        \n",
    "        # Get top c points by LOF rank\n",
    "        top_lof = set(df.nsmallest(c, lof_rank_col).index)\n",
    "        \n",
    "        # Get all points that are in top-c of at least one method\n",
    "        all_top = top_knn.union(top_lof)\n",
    "        \n",
    "        for idx in all_top:\n",
    "            in_knn = idx in top_knn\n",
    "            in_lof = idx in top_lof\n",
    "            \n",
    "            if in_knn and in_lof:\n",
    "                # Point is in both → Global outlier\n",
    "                votes_global[idx] += 1\n",
    "            elif in_lof and not in_knn:\n",
    "                # Point is only in LOF → Local outlier\n",
    "                votes_local[idx] += 1\n",
    "            # If only in k-NN, we don't vote (ambiguous case)\n",
    "    \n",
    "    # Add votes to dataframe\n",
    "    df['votes_global'] = votes_global\n",
    "    df['votes_local'] = votes_local\n",
    "    df['total_votes'] = votes_global + votes_local\n",
    "    \n",
    "    # Classify based on majority\n",
    "    classifications = []\n",
    "    confidences = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        total = votes_global[i] + votes_local[i]\n",
    "        \n",
    "        if total == 0:\n",
    "            classifications.append('normal')\n",
    "            confidences.append(0)\n",
    "        elif votes_global[i] > votes_local[i]:\n",
    "            classifications.append('global')\n",
    "            confidences.append(votes_global[i] - votes_local[i])\n",
    "        elif votes_local[i] > votes_global[i]:\n",
    "            classifications.append('local')\n",
    "            confidences.append(votes_local[i] - votes_global[i])\n",
    "        else:  # tie\n",
    "            classifications.append('tie')\n",
    "            confidences.append(0)\n",
    "    \n",
    "    df['classification'] = classifications\n",
    "    df['confidence'] = confidences\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define range of thresholds to test\n",
    "c_values = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "# Apply majority voting\n",
    "df = majority_voting_classifier(df, c_values)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"MAJORITY VOTING CLASSIFICATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTested thresholds: {c_values}\")\n",
    "print(f\"Number of threshold values: {len(c_values)}\")\n",
    "print(\"\\nClassification counts:\")\n",
    "print(df['classification'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Vote statistics by classification:\")\n",
    "print(\"-\" * 80)\n",
    "for cls in ['global', 'local', 'tie', 'normal']:\n",
    "    subset = df[df['classification'] == cls]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()}:\")\n",
    "        print(f\"  Count: {len(subset)}\")\n",
    "        print(f\"  Avg global votes: {subset['votes_global'].mean():.2f}\")\n",
    "        print(f\"  Avg local votes: {subset['votes_local'].mean():.2f}\")\n",
    "        print(f\"  Avg confidence: {subset['confidence'].mean():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classification results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Define colors for each classification\n",
    "color_map = {\n",
    "    'normal': 'lightgray',\n",
    "    'global': 'red',\n",
    "    'local': 'blue',\n",
    "    'tie': 'purple'\n",
    "}\n",
    "\n",
    "# Plot 1: Classification (categorical colors)\n",
    "ax1 = axes[0]\n",
    "for cls in ['normal', 'global', 'local', 'tie']:\n",
    "    mask = df['classification'] == cls\n",
    "    if mask.sum() > 0:\n",
    "        ax1.scatter(\n",
    "            df.loc[mask, 'attribute_1'],\n",
    "            df.loc[mask, 'attribute_2'],\n",
    "            c=color_map[cls],\n",
    "            s=50 if cls in ['global', 'local'] else 20,\n",
    "            alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "            label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "            edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title('Local vs Global Outlier Classification\\n(Majority Voting)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Confidence scores (only for classified anomalies)\n",
    "ax2 = axes[1]\n",
    "anomaly_mask = df['classification'].isin(['global', 'local'])\n",
    "normal_mask = ~anomaly_mask\n",
    "\n",
    "# Plot normal points in background\n",
    "ax2.scatter(\n",
    "    df.loc[normal_mask, 'attribute_1'],\n",
    "    df.loc[normal_mask, 'attribute_2'],\n",
    "    c='lightgray',\n",
    "    s=20,\n",
    "    alpha=0.3,\n",
    "    label='Normal/Tie'\n",
    ")\n",
    "\n",
    "# Plot anomalies colored by confidence\n",
    "scatter = ax2.scatter(\n",
    "    df.loc[anomaly_mask, 'attribute_1'],\n",
    "    df.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df.loc[anomaly_mask, 'confidence'],\n",
    "    cmap='viridis',\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title('Classification Confidence\\n(Vote Margin)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter, ax=ax2)\n",
    "cbar.set_label('Confidence (vote difference)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed comparison with ground truth labels\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Plot 1: Ground Truth Labels\n",
    "ax1 = axes[0, 0]\n",
    "for is_out, color, label in [(0, 'blue', 'Normal'), (1, 'red', 'Outlier')]:\n",
    "    mask = df['is_outlier'] == is_out\n",
    "    ax1.scatter(\n",
    "        df.loc[mask, 'attribute_1'],\n",
    "        df.loc[mask, 'attribute_2'],\n",
    "        c=color,\n",
    "        s=40 if is_out else 20,\n",
    "        alpha=0.6,\n",
    "        label=f'{label} ({mask.sum()})',\n",
    "        marker='x' if is_out else 'o',\n",
    "        edgecolors='black' if is_out else 'none',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "ax1.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax1.set_title('Ground Truth Labels', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Our Classification\n",
    "ax2 = axes[0, 1]\n",
    "for cls, color in [('normal', 'lightgray'), ('global', 'red'), ('local', 'blue'), ('tie', 'purple')]:\n",
    "    mask = df['classification'] == cls\n",
    "    if mask.sum() > 0:\n",
    "        ax2.scatter(\n",
    "            df.loc[mask, 'attribute_1'],\n",
    "            df.loc[mask, 'attribute_2'],\n",
    "            c=color,\n",
    "            s=50 if cls in ['global', 'local'] else 20,\n",
    "            alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "            label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "            edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "ax2.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax2.set_title('Majority Vote Classification', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='best', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Voting details - Global votes\n",
    "ax3 = axes[1, 0]\n",
    "anomaly_mask = df['classification'].isin(['global', 'local'])\n",
    "normal_mask = ~anomaly_mask\n",
    "\n",
    "ax3.scatter(df.loc[normal_mask, 'attribute_1'], df.loc[normal_mask, 'attribute_2'],\n",
    "           c='lightgray', s=15, alpha=0.2)\n",
    "scatter3 = ax3.scatter(\n",
    "    df.loc[anomaly_mask, 'attribute_1'],\n",
    "    df.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df.loc[anomaly_mask, 'votes_global'],\n",
    "    cmap='Reds',\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax3.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax3.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax3.set_title('Global Votes (higher = more global)', fontsize=13, fontweight='bold')\n",
    "cbar3 = plt.colorbar(scatter3, ax=ax3)\n",
    "cbar3.set_label('Global votes', fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Voting details - Local votes\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(df.loc[normal_mask, 'attribute_1'], df.loc[normal_mask, 'attribute_2'],\n",
    "           c='lightgray', s=15, alpha=0.2)\n",
    "scatter4 = ax4.scatter(\n",
    "    df.loc[anomaly_mask, 'attribute_1'],\n",
    "    df.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df.loc[anomaly_mask, 'votes_local'],\n",
    "    cmap='Blues',\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax4.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax4.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax4.set_title('Local Votes (higher = more local)', fontsize=13, fontweight='bold')\n",
    "cbar4 = plt.colorbar(scatter4, ax=ax4)\n",
    "cbar4.set_label('Local votes', fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis: How do our classifications align with ground truth?\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASSIFICATION vs GROUND TRUTH ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cross-tabulation\n",
    "print(\"\\nCross-tabulation: Classification vs Ground Truth\")\n",
    "print(\"-\" * 80)\n",
    "crosstab = pd.crosstab(\n",
    "    df['classification'], \n",
    "    df['is_outlier'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "crosstab.columns = ['Normal (GT)', 'Outlier (GT)', 'Total']\n",
    "print(crosstab)\n",
    "\n",
    "# Among ground truth outliers, how are they classified?\n",
    "gt_outliers = df[df['is_outlier'] == 1]\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GROUND TRUTH OUTLIERS BREAKDOWN\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total ground truth outliers: {len(gt_outliers)}\")\n",
    "print(\"\\nHow are they classified?\")\n",
    "for cls in ['global', 'local', 'tie', 'normal']:\n",
    "    count = (gt_outliers['classification'] == cls).sum()\n",
    "    pct = count / len(gt_outliers) * 100 if len(gt_outliers) > 0 else 0\n",
    "    print(f\"  {cls.capitalize():10s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Show top examples of each type\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP EXAMPLES BY CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cls in ['global', 'local']:\n",
    "    subset = df[df['classification'] == cls].nlargest(5, 'confidence')\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()} OUTLIERS (Top 5 by confidence):\")\n",
    "        print(\"-\" * 80)\n",
    "        cols_to_show = ['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                        'votes_global', 'votes_local', 'confidence', 'is_outlier']\n",
    "        print(subset[cols_to_show].to_string(index=True))\n",
    "\n",
    "# Statistics on ranks\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RANK STATISTICS BY CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cls in ['global', 'local']:\n",
    "    subset = df[df['classification'] == cls]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()} outliers (n={len(subset)}):\")\n",
    "        print(f\"  k-NN rank - mean: {subset['knn_rank'].mean():.1f}, median: {subset['knn_rank'].median():.1f}, min: {subset['knn_rank'].min()}, max: {subset['knn_rank'].max()}\")\n",
    "        print(f\"  LOF rank  - mean: {subset['lof_rank'].mean():.1f}, median: {subset['lof_rank'].median():.1f}, min: {subset['lof_rank'].min()}, max: {subset['lof_rank'].max()}\")\n",
    "        print(f\"  Rank diff (LOF-kNN) - mean: {(subset['lof_rank'] - subset['knn_rank']).mean():.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Experiment with Different Threshold Ranges\n",
    "\n",
    "Let's see how the classification changes with different ranges of c values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different threshold strategies\n",
    "threshold_strategies = {\n",
    "    'Fine-grained (10-100)': list(range(10, 101, 10)),\n",
    "    'Coarse (10-200, step 20)': list(range(10, 201, 20)),\n",
    "    'Wide range (5-300)': [5, 10, 20, 30, 50, 75, 100, 150, 200, 250, 300],\n",
    "    'Small thresholds (5-50)': list(range(5, 51, 5)),\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (strategy_name, c_vals) in enumerate(threshold_strategies.items()):\n",
    "    # Create a copy of original dataframe\n",
    "    df_temp = df[['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', 'is_outlier']].copy()\n",
    "    \n",
    "    # Apply classification\n",
    "    df_temp = majority_voting_classifier(df_temp, c_vals)\n",
    "    \n",
    "    # Store summary\n",
    "    summary = {\n",
    "        'Strategy': strategy_name,\n",
    "        'Thresholds': c_vals,\n",
    "        'Global': (df_temp['classification'] == 'global').sum(),\n",
    "        'Local': (df_temp['classification'] == 'local').sum(),\n",
    "        'Tie': (df_temp['classification'] == 'tie').sum(),\n",
    "        'Normal': (df_temp['classification'] == 'normal').sum(),\n",
    "    }\n",
    "    results_summary.append(summary)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    for cls, color in [('normal', 'lightgray'), ('global', 'red'), ('local', 'blue'), ('tie', 'purple')]:\n",
    "        mask = df_temp['classification'] == cls\n",
    "        if mask.sum() > 0:\n",
    "            ax.scatter(\n",
    "                df_temp.loc[mask, 'attribute_1'],\n",
    "                df_temp.loc[mask, 'attribute_2'],\n",
    "                c=color,\n",
    "                s=50 if cls in ['global', 'local'] else 15,\n",
    "                alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "                label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "                edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "                linewidth=0.5\n",
    "            )\n",
    "    \n",
    "    ax.set_xlabel('Attribute 1', fontsize=10)\n",
    "    ax.set_ylabel('Attribute 2', fontsize=10)\n",
    "    ax.set_title(f'{strategy_name}\\n(c: {min(c_vals)}-{max(c_vals)}, n={len(c_vals)})', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON OF THRESHOLD STRATEGIES\")\n",
    "print(\"=\" * 80)\n",
    "comparison_df = pd.DataFrame(results_summary)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Export the classified data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classified data\n",
    "output_file = 'dfki_classified_local_global.csv'\n",
    "output_cols = [\n",
    "    'attribute_1', 'attribute_2', \n",
    "    'is_outlier',  # ground truth\n",
    "    'knn_score', 'knn_rank',\n",
    "    'lof_score', 'lof_rank',\n",
    "    'votes_global', 'votes_local', 'total_votes',\n",
    "    'classification', 'confidence'\n",
    "]\n",
    "\n",
    "df[output_cols].to_csv(output_file, index=False)\n",
    "print(f\"✓ Results saved to: {output_file}\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {len(output_cols)}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: DFKI Artificial (3000 samples)\")\n",
    "print(f\"Thresholds tested: {c_values}\")\n",
    "print(f\"\\nClassification results:\")\n",
    "print(df['classification'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n\\nKey insights:\")\n",
    "print(f\"  • Global outliers: Points consistently ranked high by BOTH k-NN and LOF\")\n",
    "print(f\"  • Local outliers: Points ranked high by LOF but NOT by k-NN\")\n",
    "print(f\"  • Confidence: Measured by vote margin (higher = more certain)\")\n",
    "\n",
    "# Show a few example points\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE CLASSIFICATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if (df['classification'] == 'global').any():\n",
    "    print(\"\\nMost confident GLOBAL outlier:\")\n",
    "    global_example = df[df['classification'] == 'global'].nlargest(1, 'confidence')\n",
    "    print(global_example[['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                           'votes_global', 'votes_local', 'confidence']].to_string())\n",
    "\n",
    "if (df['classification'] == 'local').any():\n",
    "    print(\"\\nMost confident LOCAL outlier:\")\n",
    "    local_example = df[df['classification'] == 'local'].nlargest(1, 'confidence')\n",
    "    print(local_example[['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                          'votes_global', 'votes_local', 'confidence']].to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Cleanup and New Synthetic Dataset\n",
    "\n",
    "**Note:** The previous cells (4-12) contained repetitive code and clustering approaches. \n",
    "\n",
    "**What to keep:**\n",
    "- Cell 0: Dataset loading and visualization ✓\n",
    "- Cell 2: k-NN analysis ✓  \n",
    "- Cell 3: LOF analysis ✓\n",
    "- Cell 7: Score comparison ✓\n",
    "- Cells 14-21: Majority voting algorithm ✓\n",
    "\n",
    "**What was removed:**\n",
    "- Cells 4-6: Repetitive ratio analyses\n",
    "- Cells 8-12: Clustering-based approaches (not suitable for our problem)\n",
    "- Empty cells\n",
    "\n",
    "---\n",
    "\n",
    "## Creating a Better Synthetic Dataset\n",
    "\n",
    "Now we'll generate a synthetic dataset with **very clear local and global outliers** to properly test our majority voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic dataset with clear local and global outliers\n",
    "def generate_synthetic_dataset(n_normal=1000, n_global=20, n_local=30):\n",
    "    \"\"\"\n",
    "    Generate a synthetic 2D dataset with:\n",
    "    - Normal points in 3 main clusters\n",
    "    - Global outliers: far from all clusters\n",
    "    - Local outliers: close to a cluster but anomalous within it\n",
    "    \"\"\"\n",
    "    \n",
    "    # Main clusters (normal points)\n",
    "    cluster1 = np.random.randn(n_normal//3, 2) * 0.5 + np.array([0, 0])\n",
    "    cluster2 = np.random.randn(n_normal//3, 2) * 0.6 + np.array([5, 2])\n",
    "    cluster3 = np.random.randn(n_normal - 2*(n_normal//3), 2) * 0.55 + np.array([2, -3])\n",
    "    normal_points = np.vstack([cluster1, cluster2, cluster3])\n",
    "    \n",
    "    # Global outliers: far from all clusters, scattered\n",
    "    global_outliers = np.random.uniform(low=-8, high=10, size=(n_global, 2))\n",
    "    # Make sure they're actually far from clusters\n",
    "    mask = (np.abs(global_outliers[:, 0]) > 6) | (np.abs(global_outliers[:, 1]) > 5)\n",
    "    global_outliers = global_outliers[mask][:n_global]\n",
    "    if len(global_outliers) < n_global:\n",
    "        extra = np.random.uniform(low=[-8, 7], high=[-6, 10], size=(n_global - len(global_outliers), 2))\n",
    "        global_outliers = np.vstack([global_outliers, extra])\n",
    "    \n",
    "    # Local outliers: near cluster2 but anomalous\n",
    "    # Create points that are close to cluster2 but in low-density regions\n",
    "    local_outliers = np.random.randn(n_local, 2) * 1.5 + np.array([5, 2])\n",
    "    # Push them to the edges of the cluster\n",
    "    angles = np.linspace(0, 2*np.pi, n_local)\n",
    "    radial_offset = np.random.uniform(1.5, 2.5, n_local)\n",
    "    local_outliers[:, 0] += radial_offset * np.cos(angles)\n",
    "    local_outliers[:, 1] += radial_offset * np.sin(angles)\n",
    "    \n",
    "    # Combine all points\n",
    "    X = np.vstack([normal_points, global_outliers, local_outliers])\n",
    "    \n",
    "    # Create labels\n",
    "    labels = np.array(['normal'] * n_normal + \n",
    "                      ['global'] * n_global + \n",
    "                      ['local'] * n_local)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'attribute_1': X[:, 0],\n",
    "        'attribute_2': X[:, 1],\n",
    "        'true_label': labels,\n",
    "        'is_outlier': (labels != 'normal').astype(int)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the dataset\n",
    "df_synthetic = generate_synthetic_dataset(n_normal=1000, n_global=20, n_local=30)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTHETIC DATASET GENERATED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset shape: {df_synthetic.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df_synthetic['true_label'].value_counts())\n",
    "print(f\"\\nTotal outliers: {df_synthetic['is_outlier'].sum()}\")\n",
    "\n",
    "# Visualize the synthetic dataset\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "colors = {'normal': 'lightblue', 'global': 'red', 'local': 'orange'}\n",
    "markers = {'normal': 'o', 'global': 'x', 'local': '^'}\n",
    "sizes = {'normal': 20, 'global': 100, 'local': 80}\n",
    "\n",
    "for label in ['normal', 'global', 'local']:\n",
    "    mask = df_synthetic['true_label'] == label\n",
    "    ax.scatter(\n",
    "        df_synthetic.loc[mask, 'attribute_1'],\n",
    "        df_synthetic.loc[mask, 'attribute_2'],\n",
    "        c=colors[label],\n",
    "        marker=markers[label],\n",
    "        s=sizes[label],\n",
    "        alpha=0.7 if label == 'normal' else 0.9,\n",
    "        label=f'{label.capitalize()} ({mask.sum()})',\n",
    "        edgecolors='black' if label != 'normal' else 'none',\n",
    "        linewidth=1.5 if label != 'normal' else 0\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=13)\n",
    "ax.set_ylabel('Attribute 2', fontsize=13)\n",
    "ax.set_title('Synthetic Dataset with Clear Local and Global Outliers', \n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply k-NN and LOF to the synthetic dataset\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Prepare data\n",
    "X_synthetic = df_synthetic[['attribute_1', 'attribute_2']].values\n",
    "scaler = MinMaxScaler()\n",
    "X_synthetic_normalized = scaler.fit_transform(X_synthetic)\n",
    "\n",
    "# Run k-NN\n",
    "k = 20\n",
    "print(f\"Running k-NN with k={k}...\")\n",
    "knn_detector = KNN(n_neighbors=k, contamination=0.05)\n",
    "knn_detector.fit(X_synthetic_normalized)\n",
    "knn_scores = knn_detector.decision_scores_\n",
    "\n",
    "# Calculate ranks\n",
    "sorted_indices = np.argsort(knn_scores)[::-1]\n",
    "knn_ranks = np.empty_like(knn_scores, dtype=int)\n",
    "knn_ranks[sorted_indices] = np.arange(1, len(knn_scores) + 1)\n",
    "\n",
    "df_synthetic['knn_score'] = knn_scores\n",
    "df_synthetic['knn_rank'] = knn_ranks\n",
    "\n",
    "# Run LOF\n",
    "print(f\"Running LOF with k={k}...\")\n",
    "lof_detector = LOF(n_neighbors=k, contamination=0.05)\n",
    "lof_detector.fit(X_synthetic_normalized)\n",
    "lof_scores = lof_detector.decision_scores_\n",
    "\n",
    "# Calculate ranks\n",
    "sorted_indices = np.argsort(lof_scores)[::-1]\n",
    "lof_ranks = np.empty_like(lof_scores, dtype=int)\n",
    "lof_ranks[sorted_indices] = np.arange(1, len(lof_scores) + 1)\n",
    "\n",
    "df_synthetic['lof_score'] = lof_scores\n",
    "df_synthetic['lof_rank'] = lof_ranks\n",
    "\n",
    "print(\"✓ k-NN and LOF analysis complete\")\n",
    "\n",
    "# Visualize scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# k-NN scores\n",
    "ax1 = axes[0]\n",
    "for label in ['normal', 'global', 'local']:\n",
    "    mask = df_synthetic['true_label'] == label\n",
    "    scatter = ax1.scatter(\n",
    "        df_synthetic.loc[mask, 'attribute_1'],\n",
    "        df_synthetic.loc[mask, 'attribute_2'],\n",
    "        c=df_synthetic.loc[mask, 'knn_score'],\n",
    "        cmap='viridis',\n",
    "        s=50 if label != 'normal' else 20,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black' if label != 'normal' else 'none',\n",
    "        linewidth=1 if label != 'normal' else 0,\n",
    "        vmin=knn_scores.min(),\n",
    "        vmax=knn_scores.max()\n",
    "    )\n",
    "ax1.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax1.set_title(f'k-NN Scores (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# LOF scores\n",
    "ax2 = axes[1]\n",
    "for label in ['normal', 'global', 'local']:\n",
    "    mask = df_synthetic['true_label'] == label\n",
    "    scatter = ax2.scatter(\n",
    "        df_synthetic.loc[mask, 'attribute_1'],\n",
    "        df_synthetic.loc[mask, 'attribute_2'],\n",
    "        c=df_synthetic.loc[mask, 'lof_score'],\n",
    "        cmap='viridis',\n",
    "        s=50 if label != 'normal' else 20,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black' if label != 'normal' else 'none',\n",
    "        linewidth=1 if label != 'normal' else 0,\n",
    "        vmin=lof_scores.min(),\n",
    "        vmax=lof_scores.max()\n",
    "    )\n",
    "ax2.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax2.set_title(f'LOF Scores (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter, ax=ax2)\n",
    "cbar2.set_label('Anomaly Score', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply majority voting classifier to synthetic dataset\n",
    "# Since we have 50 outliers (20 global + 30 local), use thresholds around that range\n",
    "\n",
    "# Define thresholds centered around the true number of outliers\n",
    "c_values_synthetic = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 70, 80, 100]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"APPLYING MAJORITY VOTING TO SYNTHETIC DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTrue outliers: {df_synthetic['is_outlier'].sum()}\")\n",
    "print(f\"  - Global: {(df_synthetic['true_label'] == 'global').sum()}\")\n",
    "print(f\"  - Local: {(df_synthetic['true_label'] == 'local').sum()}\")\n",
    "print(f\"\\nTesting thresholds: {c_values_synthetic}\")\n",
    "print()\n",
    "\n",
    "# Apply the classifier\n",
    "df_synthetic = majority_voting_classifier(df_synthetic, c_values_synthetic)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nClassification counts:\")\n",
    "print(df_synthetic['classification'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Vote statistics by classification:\")\n",
    "print(\"-\" * 80)\n",
    "for cls in ['global', 'local', 'tie', 'normal']:\n",
    "    subset = df_synthetic[df_synthetic['classification'] == cls]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()}:\")\n",
    "        print(f\"  Count: {len(subset)}\")\n",
    "        print(f\"  Avg global votes: {subset['votes_global'].mean():.2f}\")\n",
    "        print(f\"  Avg local votes: {subset['votes_local'].mean():.2f}\")\n",
    "        print(f\"  Avg confidence: {subset['confidence'].mean():.2f}\")\n",
    "\n",
    "# Compare with ground truth\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GROUND TRUTH COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cross-tabulation\n",
    "print(\"\\nClassification vs True Label:\")\n",
    "crosstab = pd.crosstab(\n",
    "    df_synthetic['classification'], \n",
    "    df_synthetic['true_label'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "print(crosstab)\n",
    "\n",
    "# Check how well we identified each type\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Performance by True Label:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for true_label in ['global', 'local', 'normal']:\n",
    "    subset = df_synthetic[df_synthetic['true_label'] == true_label]\n",
    "    print(f\"\\n{true_label.upper()} (n={len(subset)}):\")\n",
    "    if len(subset) > 0:\n",
    "        for cls in ['global', 'local', 'tie', 'normal']:\n",
    "            count = (subset['classification'] == cls).sum()\n",
    "            pct = count / len(subset) * 100\n",
    "            if count > 0:\n",
    "                print(f\"  Classified as {cls}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classification results on synthetic dataset\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 16))\n",
    "\n",
    "# Plot 1: Ground Truth\n",
    "ax1 = axes[0, 0]\n",
    "for label, color, marker, size in [\n",
    "    ('normal', 'lightblue', 'o', 20),\n",
    "    ('global', 'red', 'x', 100),\n",
    "    ('local', 'orange', '^', 80)\n",
    "]:\n",
    "    mask = df_synthetic['true_label'] == label\n",
    "    ax1.scatter(\n",
    "        df_synthetic.loc[mask, 'attribute_1'],\n",
    "        df_synthetic.loc[mask, 'attribute_2'],\n",
    "        c=color,\n",
    "        marker=marker,\n",
    "        s=size,\n",
    "        alpha=0.7 if label == 'normal' else 0.9,\n",
    "        label=f'{label.capitalize()} ({mask.sum()})',\n",
    "        edgecolors='black' if label != 'normal' else 'none',\n",
    "        linewidth=1.5 if label != 'normal' else 0\n",
    "    )\n",
    "ax1.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax1.set_title('Ground Truth Labels', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Our Classification\n",
    "ax2 = axes[0, 1]\n",
    "color_map = {'normal': 'lightgray', 'global': 'red', 'local': 'blue', 'tie': 'purple'}\n",
    "for cls in ['normal', 'global', 'local', 'tie']:\n",
    "    mask = df_synthetic['classification'] == cls\n",
    "    if mask.sum() > 0:\n",
    "        ax2.scatter(\n",
    "            df_synthetic.loc[mask, 'attribute_1'],\n",
    "            df_synthetic.loc[mask, 'attribute_2'],\n",
    "            c=color_map[cls],\n",
    "            s=50 if cls in ['global', 'local'] else 20,\n",
    "            alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "            label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "            edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "ax2.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax2.set_title('Majority Vote Classification', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='best', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Global Votes\n",
    "ax3 = axes[1, 0]\n",
    "anomaly_mask = df_synthetic['classification'].isin(['global', 'local'])\n",
    "normal_mask = ~anomaly_mask\n",
    "\n",
    "ax3.scatter(df_synthetic.loc[normal_mask, 'attribute_1'], \n",
    "            df_synthetic.loc[normal_mask, 'attribute_2'],\n",
    "           c='lightgray', s=15, alpha=0.2)\n",
    "scatter3 = ax3.scatter(\n",
    "    df_synthetic.loc[anomaly_mask, 'attribute_1'],\n",
    "    df_synthetic.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df_synthetic.loc[anomaly_mask, 'votes_global'],\n",
    "    cmap='Reds',\n",
    "    s=60,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax3.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax3.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax3.set_title('Global Votes (higher = more global)', fontsize=13, fontweight='bold')\n",
    "cbar3 = plt.colorbar(scatter3, ax=ax3)\n",
    "cbar3.set_label('Global votes', fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Local Votes\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(df_synthetic.loc[normal_mask, 'attribute_1'], \n",
    "            df_synthetic.loc[normal_mask, 'attribute_2'],\n",
    "           c='lightgray', s=15, alpha=0.2)\n",
    "scatter4 = ax4.scatter(\n",
    "    df_synthetic.loc[anomaly_mask, 'attribute_1'],\n",
    "    df_synthetic.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df_synthetic.loc[anomaly_mask, 'votes_local'],\n",
    "    cmap='Blues',\n",
    "    s=60,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax4.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax4.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax4.set_title('Local Votes (higher = more local)', fontsize=13, fontweight='bold')\n",
    "cbar4 = plt.colorbar(scatter4, ax=ax4)\n",
    "cbar4.set_label('Local votes', fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some example classifications\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE CLASSIFICATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for true_label in ['global', 'local']:\n",
    "    print(f\"\\n{true_label.upper()} OUTLIERS (showing top 5 by confidence):\")\n",
    "    print(\"-\" * 80)\n",
    "    subset = df_synthetic[df_synthetic['true_label'] == true_label].nlargest(5, 'confidence')\n",
    "    cols = ['attribute_1', 'attribute_2', 'true_label', 'classification', \n",
    "            'knn_rank', 'lof_rank', 'votes_global', 'votes_local', 'confidence']\n",
    "    print(subset[cols].to_string(index=False))\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results of synthetic dataset\n",
    "output_file_synthetic = 'synthetic_classified_local_global.csv'\n",
    "output_cols = [\n",
    "    'attribute_1', 'attribute_2',\n",
    "    'true_label', 'is_outlier',\n",
    "    'knn_score', 'knn_rank',\n",
    "    'lof_score', 'lof_rank',\n",
    "    'votes_global', 'votes_local', 'total_votes',\n",
    "    'classification', 'confidence'\n",
    "]\n",
    "\n",
    "df_synthetic[output_cols].to_csv(output_file_synthetic, index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL RESULTS - SYNTHETIC DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n✓ Results saved to: {output_file_synthetic}\")\n",
    "print(f\"  Rows: {len(df_synthetic)}\")\n",
    "print(f\"  Columns: {len(output_cols)}\")\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION ACCURACY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For global outliers\n",
    "global_true = df_synthetic['true_label'] == 'global'\n",
    "global_pred = df_synthetic['classification'] == 'global'\n",
    "global_correct = (global_true & global_pred).sum()\n",
    "global_total = global_true.sum()\n",
    "global_accuracy = (global_correct / global_total * 100) if global_total > 0 else 0\n",
    "\n",
    "print(f\"\\nGlobal Outliers:\")\n",
    "print(f\"  True positives: {global_correct}/{global_total} ({global_accuracy:.1f}%)\")\n",
    "print(f\"  Misclassified as local: {(global_true & (df_synthetic['classification'] == 'local')).sum()}\")\n",
    "print(f\"  Misclassified as normal: {(global_true & (df_synthetic['classification'] == 'normal')).sum()}\")\n",
    "\n",
    "# For local outliers\n",
    "local_true = df_synthetic['true_label'] == 'local'\n",
    "local_pred = df_synthetic['classification'] == 'local'\n",
    "local_correct = (local_true & local_pred).sum()\n",
    "local_total = local_true.sum()\n",
    "local_accuracy = (local_correct / local_total * 100) if local_total > 0 else 0\n",
    "\n",
    "print(f\"\\nLocal Outliers:\")\n",
    "print(f\"  True positives: {local_correct}/{local_total} ({local_accuracy:.1f}%)\")\n",
    "print(f\"  Misclassified as global: {(local_true & (df_synthetic['classification'] == 'global')).sum()}\")\n",
    "print(f\"  Misclassified as normal: {(local_true & (df_synthetic['classification'] == 'normal')).sum()}\")\n",
    "\n",
    "# Overall accuracy\n",
    "outlier_true = df_synthetic['is_outlier'] == 1\n",
    "outlier_detected = df_synthetic['classification'].isin(['global', 'local'])\n",
    "outlier_correct = (outlier_true & outlier_detected).sum()\n",
    "outlier_total = outlier_true.sum()\n",
    "outlier_accuracy = (outlier_correct / outlier_total * 100) if outlier_total > 0 else 0\n",
    "\n",
    "print(f\"\\nOverall Outlier Detection:\")\n",
    "print(f\"  Detected: {outlier_correct}/{outlier_total} ({outlier_accuracy:.1f}%)\")\n",
    "\n",
    "# Normal points\n",
    "normal_true = df_synthetic['true_label'] == 'normal'\n",
    "normal_pred = df_synthetic['classification'] == 'normal'\n",
    "normal_correct = (normal_true & normal_pred).sum()\n",
    "normal_total = normal_true.sum()\n",
    "normal_accuracy = (normal_correct / normal_total * 100) if normal_total > 0 else 0\n",
    "\n",
    "print(f\"\\nNormal Points:\")\n",
    "print(f\"  Correctly classified: {normal_correct}/{normal_total} ({normal_accuracy:.1f}%)\")\n",
    "print(f\"  False positives (as global): {(normal_true & (df_synthetic['classification'] == 'global')).sum()}\")\n",
    "print(f\"  False positives (as local): {(normal_true & (df_synthetic['classification'] == 'local')).sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\n✓ Analysis complete! The majority voting algorithm successfully distinguishes\")\n",
    "print(\"  between local and global outliers.\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What Changed:\n",
    "\n",
    "1. **Removed redundant code**: The voting algorithm is now defined once (Cell 14) and reused\n",
    "2. **Removed clustering approaches**: Cells 4-6, 8-12 contained clustering-based methods that assume spherical data\n",
    "3. **Optimized thresholds**: Using ranges close to the true number of outliers for better accuracy\n",
    "4. **Created synthetic dataset**: With clear local (near clusters) and global (far from all) outliers\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "✓ **Global outliers**: Detected by BOTH k-NN and LOF (far from everything)  \n",
    "✓ **Local outliers**: Detected by LOF only (anomalous within their neighborhood)  \n",
    "✓ **Majority voting**: Robust across multiple thresholds, reduces single-threshold sensitivity\n",
    "\n",
    "### Cells to Delete Manually:\n",
    "\n",
    "You can now safely delete these redundant cells:\n",
    "- **Cell 1**: Empty\n",
    "- **Cells 4-6**: Repetitive ratio analyses (replaced by cells 14-21)\n",
    "- **Cells 8-12**: Clustering approaches (not suitable)\n",
    "- **Cell 13**: Empty\n",
    "\n",
    "### Keep These Cells:\n",
    "\n",
    "- **Cell 0**: Dataset loading ✓\n",
    "- **Cell 2**: k-NN analysis ✓\n",
    "- **Cell 3**: LOF analysis ✓  \n",
    "- **Cell 7**: Score comparison ✓\n",
    "- **Cells 14-21**: Majority voting algorithm (DFKI dataset) ✓\n",
    "- **Cells 22-28**: Synthetic dataset + majority voting (NEW) ✓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Majority Voting Algorithm for Global vs Local Outlier Classification\n",
    "\n",
    "Key Idea:\n",
    "- For each threshold c (top c anomalies):\n",
    "  - If point is in top-c for BOTH kNN AND LOF → vote \"global\"\n",
    "  - If point is in top-c for LOF but NOT kNN → vote \"local\"\n",
    "- Aggregate votes across many c values\n",
    "- Classify by majority vote\n",
    "\"\"\"\n",
    "\n",
    "def majority_vote_classification(df, c_range, knn_rank_col='knn_rank', lof_rank_col='lof_rank'):\n",
    "    \"\"\"\n",
    "    Classify outliers as global or local using majority voting across multiple thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Must contain knn_rank and lof_rank columns\n",
    "    c_range : list or range\n",
    "        List of threshold values to test (e.g., [10, 20, 30, ..., 100])\n",
    "    knn_rank_col : str\n",
    "        Column name for k-NN ranks\n",
    "    lof_rank_col : str\n",
    "        Column name for LOF ranks\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added columns:\n",
    "        - 'global_votes': number of times classified as global\n",
    "        - 'local_votes': number of times classified as local\n",
    "        - 'total_votes': total votes received\n",
    "        - 'classification': 'global', 'local', or 'normal' (no votes)\n",
    "        - 'confidence': ratio of majority votes to total votes\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = len(df)\n",
    "    \n",
    "    # Initialize vote counters\n",
    "    global_votes = np.zeros(n_samples, dtype=int)\n",
    "    local_votes = np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    print(f\"Running majority voting across c = {list(c_range)}\")\n",
    "    print(f\"Total thresholds to test: {len(list(c_range))}\")\n",
    "    print()\n",
    "    \n",
    "    # Iterate through each threshold value\n",
    "    for c in c_range:\n",
    "        # Get top c indices for each algorithm\n",
    "        top_knn = set(df.nsmallest(c, knn_rank_col).index)\n",
    "        top_lof = set(df.nsmallest(c, lof_rank_col).index)\n",
    "        \n",
    "        # Points in both → global vote\n",
    "        global_outliers = top_knn & top_lof\n",
    "        \n",
    "        # Points in LOF but not kNN → local vote\n",
    "        local_outliers = top_lof - top_knn\n",
    "        \n",
    "        # Record votes\n",
    "        for idx in global_outliers:\n",
    "            global_votes[idx] += 1\n",
    "        \n",
    "        for idx in local_outliers:\n",
    "            local_votes[idx] += 1\n",
    "    \n",
    "    # Add results to dataframe\n",
    "    df_result = df.copy()\n",
    "    df_result['global_votes'] = global_votes\n",
    "    df_result['local_votes'] = local_votes\n",
    "    df_result['total_votes'] = global_votes + local_votes\n",
    "    \n",
    "    # Classify based on majority\n",
    "    classifications = []\n",
    "    confidences = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        g_votes = global_votes[i]\n",
    "        l_votes = local_votes[i]\n",
    "        total = g_votes + l_votes\n",
    "        \n",
    "        if total == 0:\n",
    "            classifications.append('normal')\n",
    "            confidences.append(0.0)\n",
    "        elif g_votes > l_votes:\n",
    "            classifications.append('global')\n",
    "            confidences.append(g_votes / total)\n",
    "        elif l_votes > g_votes:\n",
    "            classifications.append('local')\n",
    "            confidences.append(l_votes / total)\n",
    "        else:  # tie\n",
    "            classifications.append('tie')\n",
    "            confidences.append(0.5)\n",
    "    \n",
    "    df_result['classification'] = classifications\n",
    "    df_result['confidence'] = confidences\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLASSIFICATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Global outliers: {sum(np.array(classifications) == 'global')}\")\n",
    "    print(f\"Local outliers:  {sum(np.array(classifications) == 'local')}\")\n",
    "    print(f\"Ties:            {sum(np.array(classifications) == 'tie')}\")\n",
    "    print(f\"Normal points:   {sum(np.array(classifications) == 'normal')}\")\n",
    "    print()\n",
    "    \n",
    "    # Statistics on confidence\n",
    "    voted_mask = np.array(classifications) != 'normal'\n",
    "    if voted_mask.any():\n",
    "        voted_confidences = np.array(confidences)[voted_mask]\n",
    "        print(f\"Confidence statistics (for classified points):\")\n",
    "        print(f\"  Mean: {voted_confidences.mean():.3f}\")\n",
    "        print(f\"  Min:  {voted_confidences.min():.3f}\")\n",
    "        print(f\"  Max:  {voted_confidences.max():.3f}\")\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "\n",
    "def plot_classification_results(df, max_c, attr1='attribute_1', attr2='attribute_2'):\n",
    "    \"\"\"\n",
    "    Visualize the classification results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Must contain 'classification' and 'confidence' columns\n",
    "    max_c : int\n",
    "        Maximum c value used (for plot title)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create color map\n",
    "    color_map = {\n",
    "        'global': 'red',\n",
    "        'local': 'blue',\n",
    "        'tie': 'purple',\n",
    "        'normal': 'lightgray'\n",
    "    }\n",
    "    \n",
    "    colors = [color_map[c] for c in df['classification']]\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # Plot 1: Classification with consistent colors\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Plot normal points first (background)\n",
    "    normal_mask = df['classification'] == 'normal'\n",
    "    ax1.scatter(df.loc[normal_mask, attr1], \n",
    "                df.loc[normal_mask, attr2],\n",
    "                c='lightgray', s=20, alpha=0.3, label='Normal', zorder=1)\n",
    "    \n",
    "    # Plot classified outliers\n",
    "    for cls, color, label, marker in [\n",
    "        ('global', 'red', 'Global Outlier', 'o'),\n",
    "        ('local', 'blue', 'Local Outlier', '^'),\n",
    "        ('tie', 'purple', 'Tie', 's')\n",
    "    ]:\n",
    "        mask = df['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax1.scatter(df.loc[mask, attr1], \n",
    "                       df.loc[mask, attr2],\n",
    "                       c=color, s=80, alpha=0.8, \n",
    "                       edgecolors='black', linewidth=0.5,\n",
    "                       label=label, marker=marker, zorder=3)\n",
    "    \n",
    "    ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax1.set_title(f'Global vs Local Outlier Classification\\n(Majority Voting, max c={max_c})', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Confidence scores\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Plot normal points\n",
    "    ax2.scatter(df.loc[normal_mask, attr1], \n",
    "                df.loc[normal_mask, attr2],\n",
    "                c='lightgray', s=20, alpha=0.3, label='Normal', zorder=1)\n",
    "    \n",
    "    # Plot classified points with confidence coloring\n",
    "    classified_mask = df['classification'] != 'normal'\n",
    "    if classified_mask.any():\n",
    "        scatter = ax2.scatter(df.loc[classified_mask, attr1], \n",
    "                             df.loc[classified_mask, attr2],\n",
    "                             c=df.loc[classified_mask, 'confidence'],\n",
    "                             cmap='RdYlGn', s=80, alpha=0.8,\n",
    "                             edgecolors='black', linewidth=0.5,\n",
    "                             vmin=0.5, vmax=1.0, zorder=3)\n",
    "        \n",
    "        cbar = plt.colorbar(scatter, ax=ax2)\n",
    "        cbar.set_label('Classification Confidence', fontsize=11)\n",
    "    \n",
    "    ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax2.set_title(f'Classification Confidence Scores\\n(Higher = stronger agreement)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional plot: Vote distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    classified_mask = df['classification'] != 'normal'\n",
    "    if classified_mask.any():\n",
    "        scatter = ax.scatter(df.loc[classified_mask, 'global_votes'], \n",
    "                           df.loc[classified_mask, 'local_votes'],\n",
    "                           c=df.loc[classified_mask, 'classification'].map(color_map),\n",
    "                           s=60, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Add diagonal line (tie line)\n",
    "        max_votes = max(df['global_votes'].max(), df['local_votes'].max())\n",
    "        ax.plot([0, max_votes], [0, max_votes], 'k--', alpha=0.3, linewidth=1, label='Tie line')\n",
    "        \n",
    "        ax.set_xlabel('Global Votes', fontsize=12)\n",
    "        ax.set_ylabel('Local Votes', fontsize=12)\n",
    "        ax.set_title('Vote Distribution', fontsize=13, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add legend manually\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='red', edgecolor='black', label='Global'),\n",
    "            Patch(facecolor='blue', edgecolor='black', label='Local'),\n",
    "            Patch(facecolor='purple', edgecolor='black', label='Tie')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='best', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Functions loaded successfully!\")\n",
    "print(\"\\nUsage example:\")\n",
    "print(\"  c_range = range(10, 101, 5)  # Test c from 10 to 100, step 5\")\n",
    "print(\"  df_classified = majority_vote_classification(df, c_range)\")\n",
    "print(\"  plot_classification_results(df_classified, max_c=100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the majority voting classification\n",
    "# Test with c values from 10 to 150 in steps of 5\n",
    "\n",
    "c_range = range(10, 151, 5)  # [10, 15, 20, ..., 150]\n",
    "\n",
    "df_classified = majority_vote_classification(df, c_range)\n",
    "\n",
    "# Visualize results\n",
    "plot_classification_results(df_classified, max_c=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis: Compare with ground truth and explore different c ranges\n",
    "\n",
    "def analyze_classification_vs_ground_truth(df_classified):\n",
    "    \"\"\"\n",
    "    Analyze how classified outliers relate to ground truth labels.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON WITH GROUND TRUTH\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get ground truth outliers\n",
    "    true_outliers = df_classified[df_classified['is_outlier'] == 1]\n",
    "    true_normals = df_classified[df_classified['is_outlier'] == 0]\n",
    "    \n",
    "    print(f\"\\nGround truth distribution:\")\n",
    "    print(f\"  True outliers: {len(true_outliers)}\")\n",
    "    print(f\"  True normals:  {len(true_normals)}\")\n",
    "    \n",
    "    # Among true outliers, how are they classified?\n",
    "    print(f\"\\nClassification of TRUE OUTLIERS:\")\n",
    "    outlier_classifications = true_outliers['classification'].value_counts()\n",
    "    for cls, count in outlier_classifications.items():\n",
    "        pct = count / len(true_outliers) * 100\n",
    "        print(f\"  {cls:10s}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Among classified global outliers, what % are true outliers?\n",
    "    print(f\"\\nPrecision check:\")\n",
    "    for cls in ['global', 'local']:\n",
    "        classified = df_classified[df_classified['classification'] == cls]\n",
    "        if len(classified) > 0:\n",
    "            true_positive = (classified['is_outlier'] == 1).sum()\n",
    "            precision = true_positive / len(classified) * 100\n",
    "            print(f\"  {cls:10s}: {true_positive}/{len(classified)} are true outliers ({precision:.1f}%)\")\n",
    "    \n",
    "    # Visualize ground truth vs classification\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # Plot 1: Ground truth\n",
    "    ax1 = axes[0]\n",
    "    normal_mask = df_classified['is_outlier'] == 0\n",
    "    outlier_mask = df_classified['is_outlier'] == 1\n",
    "    \n",
    "    ax1.scatter(df_classified.loc[normal_mask, 'attribute_1'], \n",
    "                df_classified.loc[normal_mask, 'attribute_2'],\n",
    "                c='lightgray', s=20, alpha=0.5, label='Normal')\n",
    "    ax1.scatter(df_classified.loc[outlier_mask, 'attribute_1'], \n",
    "                df_classified.loc[outlier_mask, 'attribute_2'],\n",
    "                c='black', s=80, alpha=0.8, marker='x', \n",
    "                edgecolors='red', linewidth=1.5, label='True Outlier')\n",
    "    \n",
    "    ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax1.set_title('Ground Truth Labels', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Our classification overlaid on ground truth\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Background: ground truth\n",
    "    ax2.scatter(df_classified.loc[normal_mask, 'attribute_1'], \n",
    "                df_classified.loc[normal_mask, 'attribute_2'],\n",
    "                c='lightgray', s=20, alpha=0.3, label='True Normal')\n",
    "    ax2.scatter(df_classified.loc[outlier_mask, 'attribute_1'], \n",
    "                df_classified.loc[outlier_mask, 'attribute_2'],\n",
    "                c='yellow', s=80, alpha=0.5, marker='x', \n",
    "                edgecolors='orange', linewidth=1, label='True Outlier')\n",
    "    \n",
    "    # Overlay: our classification\n",
    "    for cls, color, label, marker in [\n",
    "        ('global', 'red', 'Classified: Global', 'o'),\n",
    "        ('local', 'blue', 'Classified: Local', '^')\n",
    "    ]:\n",
    "        mask = df_classified['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax2.scatter(df_classified.loc[mask, 'attribute_1'], \n",
    "                       df_classified.loc[mask, 'attribute_2'],\n",
    "                       c=color, s=60, alpha=0.7, \n",
    "                       edgecolors='black', linewidth=0.5,\n",
    "                       label=label, marker=marker, zorder=3)\n",
    "    \n",
    "    ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax2.set_title('Classification Overlaid on Ground Truth', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(loc='best', fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "analyze_classification_vs_ground_truth(df_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different c ranges to test sensitivity\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TESTING DIFFERENT C RANGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_configs = [\n",
    "    {\"name\": \"Small range (10-50)\", \"c_range\": range(10, 51, 5)},\n",
    "    {\"name\": \"Medium range (10-100)\", \"c_range\": range(10, 101, 5)},\n",
    "    {\"name\": \"Large range (10-200)\", \"c_range\": range(10, 201, 10)},\n",
    "    {\"name\": \"Fine-grained (5-100, step=1)\", \"c_range\": range(5, 101, 1)},\n",
    "]\n",
    "\n",
    "results_comparison = []\n",
    "\n",
    "for config in test_configs:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing: {config['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    df_test = majority_vote_classification(df, config['c_range'])\n",
    "    \n",
    "    # Store summary\n",
    "    results_comparison.append({\n",
    "        'name': config['name'],\n",
    "        'n_thresholds': len(list(config['c_range'])),\n",
    "        'global': (df_test['classification'] == 'global').sum(),\n",
    "        'local': (df_test['classification'] == 'local').sum(),\n",
    "        'tie': (df_test['classification'] == 'tie').sum(),\n",
    "        'normal': (df_test['classification'] == 'normal').sum(),\n",
    "        'avg_confidence': df_test[df_test['classification'] != 'normal']['confidence'].mean()\n",
    "    })\n",
    "\n",
    "# Display comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON ACROSS DIFFERENT C RANGES\")\n",
    "print(\"=\"*70)\n",
    "comparison_df = pd.DataFrame(results_comparison)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize one of the configurations in detail\n",
    "print(\"\\n\\nVisualizing: Medium range (10-100)\")\n",
    "df_medium = majority_vote_classification(df, range(10, 101, 5))\n",
    "plot_classification_results(df_medium, max_c=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed inspection: Show top global and local outliers\n",
    "\n",
    "def inspect_top_outliers(df_classified, n_top=10):\n",
    "    \"\"\"\n",
    "    Display detailed information about the top global and local outliers.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"TOP {n_top} GLOBAL OUTLIERS (sorted by confidence)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    global_outliers = df_classified[df_classified['classification'] == 'global'].copy()\n",
    "    global_outliers = global_outliers.sort_values('confidence', ascending=False).head(n_top)\n",
    "    \n",
    "    cols_to_show = ['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                    'global_votes', 'local_votes', 'confidence', 'is_outlier']\n",
    "    print(global_outliers[cols_to_show].to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"TOP {n_top} LOCAL OUTLIERS (sorted by confidence)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    local_outliers = df_classified[df_classified['classification'] == 'local'].copy()\n",
    "    local_outliers = local_outliers.sort_values('confidence', ascending=False).head(n_top)\n",
    "    \n",
    "    print(local_outliers[cols_to_show].to_string())\n",
    "    \n",
    "    # Visualize these specific points\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    \n",
    "    # Background: all points\n",
    "    normal_bg = df_classified['classification'] == 'normal'\n",
    "    ax.scatter(df_classified.loc[normal_bg, 'attribute_1'], \n",
    "              df_classified.loc[normal_bg, 'attribute_2'],\n",
    "              c='lightgray', s=15, alpha=0.2, label='Other points')\n",
    "    \n",
    "    # Top global outliers\n",
    "    ax.scatter(global_outliers['attribute_1'], \n",
    "              global_outliers['attribute_2'],\n",
    "              c='red', s=150, alpha=0.7, marker='o',\n",
    "              edgecolors='darkred', linewidth=2,\n",
    "              label=f'Top {n_top} Global Outliers')\n",
    "    \n",
    "    # Top local outliers\n",
    "    ax.scatter(local_outliers['attribute_1'], \n",
    "              local_outliers['attribute_2'],\n",
    "              c='blue', s=150, alpha=0.7, marker='^',\n",
    "              edgecolors='darkblue', linewidth=2,\n",
    "              label=f'Top {n_top} Local Outliers')\n",
    "    \n",
    "    # Add labels to points\n",
    "    for idx, row in global_outliers.iterrows():\n",
    "        ax.annotate(f\"G{idx}\", \n",
    "                   (row['attribute_1'], row['attribute_2']),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=8, color='darkred', fontweight='bold')\n",
    "    \n",
    "    for idx, row in local_outliers.iterrows():\n",
    "        ax.annotate(f\"L{idx}\", \n",
    "                   (row['attribute_1'], row['attribute_2']),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=8, color='darkblue', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax.set_title(f'Top {n_top} Global vs Local Outliers', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTop global outliers:\")\n",
    "    print(f\"  Avg kNN rank: {global_outliers['knn_rank'].mean():.1f}\")\n",
    "    print(f\"  Avg LOF rank: {global_outliers['lof_rank'].mean():.1f}\")\n",
    "    print(f\"  % true outliers: {(global_outliers['is_outlier'] == 1).sum() / len(global_outliers) * 100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nTop local outliers:\")\n",
    "    print(f\"  Avg kNN rank: {local_outliers['knn_rank'].mean():.1f}\")\n",
    "    print(f\"  Avg LOF rank: {local_outliers['lof_rank'].mean():.1f}\")\n",
    "    print(f\"  % true outliers: {(local_outliers['is_outlier'] == 1).sum() / len(local_outliers) * 100:.1f}%\")\n",
    "\n",
    "\n",
    "# Run inspection\n",
    "inspect_top_outliers(df_classified, n_top=10)\n",
    "\n",
    "# Optional: Save results to CSV\n",
    "# df_classified.to_csv('classified_outliers.csv', index=True)\n",
    "# print(\"\\nResults saved to 'classified_outliers.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test with different k values for kNN and LOF\n",
    "\n",
    "def run_full_pipeline(df_original, k_knn=20, k_lof=20, c_range=range(10, 101, 5)):\n",
    "    \"\"\"\n",
    "    Complete pipeline: run kNN and LOF with specified k values, \n",
    "    then perform majority voting classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : DataFrame\n",
    "        Original dataset with 'attribute_1', 'attribute_2', and 'is_outlier' columns\n",
    "    k_knn : int\n",
    "        Number of neighbors for k-NN\n",
    "    k_lof : int\n",
    "        Number of neighbors for LOF\n",
    "    c_range : range or list\n",
    "        Range of c values for majority voting\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with all scores, ranks, and classifications\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"RUNNING FULL PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"k-NN neighbors: {k_knn}\")\n",
    "    print(f\"LOF neighbors:  {k_lof}\")\n",
    "    print(f\"Voting range:   {list(c_range)[0]} to {list(c_range)[-1]}\")\n",
    "    print()\n",
    "    \n",
    "    df_work = df_original.copy()\n",
    "    X = df_work[['attribute_1', 'attribute_2']].values\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    \n",
    "    # Run k-NN\n",
    "    print(f\"Running k-NN (k={k_knn})...\")\n",
    "    knn_detector = KNN(n_neighbors=k_knn, contamination=0.01)\n",
    "    knn_detector.fit(X_normalized)\n",
    "    knn_scores = knn_detector.decision_scores_\n",
    "    \n",
    "    sorted_indices = np.argsort(knn_scores)[::-1]\n",
    "    knn_ranks = np.empty_like(knn_scores, dtype=int)\n",
    "    knn_ranks[sorted_indices] = np.arange(1, len(knn_scores) + 1)\n",
    "    \n",
    "    df_work['knn_score'] = knn_scores\n",
    "    df_work['knn_rank'] = knn_ranks\n",
    "    \n",
    "    # Run LOF\n",
    "    print(f\"Running LOF (k={k_lof})...\")\n",
    "    lof_detector = LOF(n_neighbors=k_lof, contamination=0.01)\n",
    "    lof_detector.fit(X_normalized)\n",
    "    lof_scores = lof_detector.decision_scores_\n",
    "    \n",
    "    sorted_indices = np.argsort(lof_scores)[::-1]\n",
    "    lof_ranks = np.empty_like(lof_scores, dtype=int)\n",
    "    lof_ranks[sorted_indices] = np.arange(1, len(lof_scores) + 1)\n",
    "    \n",
    "    df_work['lof_score'] = lof_scores\n",
    "    df_work['lof_rank'] = lof_ranks\n",
    "    \n",
    "    # Majority voting classification\n",
    "    print(f\"\\nRunning majority voting...\")\n",
    "    df_result = majority_vote_classification(df_work, c_range)\n",
    "    \n",
    "    print(\"\\nPipeline complete!\")\n",
    "    return df_result\n",
    "\n",
    "\n",
    "# Example: Test with different k values\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING SENSITIVITY TO k VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Small k values (more local)\n",
    "print(\"\\n### Test 1: Small k (k=10) ###\")\n",
    "df_k10 = run_full_pipeline(df, k_knn=10, k_lof=10, c_range=range(10, 101, 5))\n",
    "plot_classification_results(df_k10, max_c=100)\n",
    "\n",
    "# Test 2: Larger k values (more global)\n",
    "print(\"\\n### Test 2: Large k (k=40) ###\")\n",
    "df_k40 = run_full_pipeline(df, k_knn=40, k_lof=40, c_range=range(10, 101, 5))\n",
    "plot_classification_results(df_k40, max_c=100)\n",
    "\n",
    "# Compare the two\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: k=10 vs k=40\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nWith k=10 (more sensitive to local structure):\")\n",
    "print(f\"  Global: {(df_k10['classification'] == 'global').sum()}\")\n",
    "print(f\"  Local:  {(df_k10['classification'] == 'local').sum()}\")\n",
    "\n",
    "print(\"\\nWith k=40 (more global perspective):\")\n",
    "print(f\"  Global: {(df_k40['classification'] == 'global').sum()}\")\n",
    "print(f\"  Local:  {(df_k40['classification'] == 'local').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Export\n",
    "\n",
    "def create_summary_report(df_classified):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary report of the classification results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_points = len(df_classified)\n",
    "    n_global = (df_classified['classification'] == 'global').sum()\n",
    "    n_local = (df_classified['classification'] == 'local').sum()\n",
    "    n_tie = (df_classified['classification'] == 'tie').sum()\n",
    "    n_normal = (df_classified['classification'] == 'normal').sum()\n",
    "    \n",
    "    print(f\"\\n1. OVERALL CLASSIFICATION\")\n",
    "    print(f\"   Total points:     {total_points}\")\n",
    "    print(f\"   Global outliers:  {n_global:4d} ({n_global/total_points*100:5.2f}%)\")\n",
    "    print(f\"   Local outliers:   {n_local:4d} ({n_local/total_points*100:5.2f}%)\")\n",
    "    print(f\"   Ties:             {n_tie:4d} ({n_tie/total_points*100:5.2f}%)\")\n",
    "    print(f\"   Normal points:    {n_normal:4d} ({n_normal/total_points*100:5.2f}%)\")\n",
    "    \n",
    "    # Confidence statistics\n",
    "    classified = df_classified[df_classified['classification'].isin(['global', 'local'])]\n",
    "    if len(classified) > 0:\n",
    "        print(f\"\\n2. CONFIDENCE STATISTICS\")\n",
    "        print(f\"   Mean confidence:  {classified['confidence'].mean():.3f}\")\n",
    "        print(f\"   Median confidence: {classified['confidence'].median():.3f}\")\n",
    "        print(f\"   Std confidence:   {classified['confidence'].std():.3f}\")\n",
    "        print(f\"   High conf (>0.8): {(classified['confidence'] > 0.8).sum()} points\")\n",
    "        print(f\"   Low conf (<0.6):  {(classified['confidence'] < 0.6).sum()} points\")\n",
    "    \n",
    "    # Ground truth comparison\n",
    "    if 'is_outlier' in df_classified.columns:\n",
    "        true_outliers = df_classified[df_classified['is_outlier'] == 1]\n",
    "        \n",
    "        print(f\"\\n3. GROUND TRUTH COMPARISON\")\n",
    "        print(f\"   True outliers in dataset: {len(true_outliers)}\")\n",
    "        print(f\"   Detected by our method:   {n_global + n_local}\")\n",
    "        \n",
    "        # Detection rate\n",
    "        detected = true_outliers['classification'].isin(['global', 'local']).sum()\n",
    "        detection_rate = detected / len(true_outliers) * 100 if len(true_outliers) > 0 else 0\n",
    "        print(f\"   Detection rate:           {detected}/{len(true_outliers)} ({detection_rate:.1f}%)\")\n",
    "        \n",
    "        # Precision\n",
    "        our_outliers = df_classified[df_classified['classification'].isin(['global', 'local'])]\n",
    "        if len(our_outliers) > 0:\n",
    "            true_positives = (our_outliers['is_outlier'] == 1).sum()\n",
    "            precision = true_positives / len(our_outliers) * 100\n",
    "            print(f\"   Precision:                {true_positives}/{len(our_outliers)} ({precision:.1f}%)\")\n",
    "        \n",
    "        # Among detected true outliers, global vs local\n",
    "        detected_outliers = true_outliers[true_outliers['classification'].isin(['global', 'local'])]\n",
    "        if len(detected_outliers) > 0:\n",
    "            n_global_true = (detected_outliers['classification'] == 'global').sum()\n",
    "            n_local_true = (detected_outliers['classification'] == 'local').sum()\n",
    "            print(f\"\\n   Among detected true outliers:\")\n",
    "            print(f\"      Classified as global: {n_global_true} ({n_global_true/len(detected_outliers)*100:.1f}%)\")\n",
    "            print(f\"      Classified as local:  {n_local_true} ({n_local_true/len(detected_outliers)*100:.1f}%)\")\n",
    "    \n",
    "    # Ranking statistics\n",
    "    if 'knn_rank' in df_classified.columns and 'lof_rank' in df_classified.columns:\n",
    "        print(f\"\\n4. RANK STATISTICS\")\n",
    "        \n",
    "        global_outliers = df_classified[df_classified['classification'] == 'global']\n",
    "        local_outliers = df_classified[df_classified['classification'] == 'local']\n",
    "        \n",
    "        if len(global_outliers) > 0:\n",
    "            print(f\"\\n   Global outliers:\")\n",
    "            print(f\"      Avg k-NN rank: {global_outliers['knn_rank'].mean():6.1f}\")\n",
    "            print(f\"      Avg LOF rank:  {global_outliers['lof_rank'].mean():6.1f}\")\n",
    "            print(f\"      Rank ratio:    {(global_outliers['lof_rank'] / global_outliers['knn_rank']).mean():.3f}\")\n",
    "        \n",
    "        if len(local_outliers) > 0:\n",
    "            print(f\"\\n   Local outliers:\")\n",
    "            print(f\"      Avg k-NN rank: {local_outliers['knn_rank'].mean():6.1f}\")\n",
    "            print(f\"      Avg LOF rank:  {local_outliers['lof_rank'].mean():6.1f}\")\n",
    "            print(f\"      Rank ratio:    {(local_outliers['lof_rank'] / local_outliers['knn_rank']).mean():.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "# Generate report for our classification\n",
    "create_summary_report(df_classified)\n",
    "\n",
    "# Optional: Save detailed results\n",
    "save_results = False  # Set to True to save\n",
    "\n",
    "if save_results:\n",
    "    output_file = 'xod_majority_voting_results.csv'\n",
    "    cols_to_save = ['attribute_1', 'attribute_2', 'is_outlier',\n",
    "                    'knn_score', 'knn_rank', 'lof_score', 'lof_rank',\n",
    "                    'global_votes', 'local_votes', 'total_votes',\n",
    "                    'classification', 'confidence']\n",
    "    df_classified[cols_to_save].to_csv(output_file, index=True)\n",
    "    print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "else:\n",
    "    print(f\"\\nTo save results, set save_results = True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Visualization: Rank Difference Analysis\n",
    "\n",
    "def visualize_rank_differences(df_classified):\n",
    "    \"\"\"\n",
    "    Visualize the relationship between k-NN and LOF ranks,\n",
    "    highlighting global vs local outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate rank difference\n",
    "    df_viz = df_classified.copy()\n",
    "    df_viz['rank_diff'] = df_viz['lof_rank'] - df_viz['knn_rank']\n",
    "    df_viz['rank_ratio'] = df_viz['lof_rank'] / (df_viz['knn_rank'] + 1)  # +1 to avoid division by zero\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # Plot 1: k-NN rank vs LOF rank\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    color_map = {'global': 'red', 'local': 'blue', 'tie': 'purple', 'normal': 'lightgray'}\n",
    "    \n",
    "    for cls in ['normal', 'tie', 'local', 'global']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            alpha = 0.2 if cls == 'normal' else 0.7\n",
    "            size = 20 if cls == 'normal' else 60\n",
    "            ax1.scatter(df_viz.loc[mask, 'knn_rank'], \n",
    "                       df_viz.loc[mask, 'lof_rank'],\n",
    "                       c=color_map[cls], s=size, alpha=alpha, \n",
    "                       label=cls.capitalize())\n",
    "    \n",
    "    # Add diagonal line (where kNN rank = LOF rank)\n",
    "    max_rank = max(df_viz['knn_rank'].max(), df_viz['lof_rank'].max())\n",
    "    ax1.plot([0, max_rank], [0, max_rank], 'k--', alpha=0.3, linewidth=1, label='Equal rank')\n",
    "    \n",
    "    ax1.set_xlabel('k-NN Rank', fontsize=12)\n",
    "    ax1.set_ylabel('LOF Rank', fontsize=12)\n",
    "    ax1.set_title('k-NN Rank vs LOF Rank', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Rank difference distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    for cls in ['global', 'local']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax2.hist(df_viz.loc[mask, 'rank_diff'], \n",
    "                    bins=30, alpha=0.6, label=cls.capitalize(),\n",
    "                    color=color_map[cls], edgecolor='black')\n",
    "    \n",
    "    ax2.axvline(x=0, color='black', linestyle='--', linewidth=2, alpha=0.5, label='No difference')\n",
    "    ax2.set_xlabel('Rank Difference (LOF - k-NN)', fontsize=12)\n",
    "    ax2.set_ylabel('Count', fontsize=12)\n",
    "    ax2.set_title('Distribution of Rank Differences', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(loc='best', fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: Spatial distribution colored by rank difference\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    classified_mask = df_viz['classification'] != 'normal'\n",
    "    \n",
    "    # Background\n",
    "    ax3.scatter(df_viz.loc[~classified_mask, 'attribute_1'],\n",
    "               df_viz.loc[~classified_mask, 'attribute_2'],\n",
    "               c='lightgray', s=20, alpha=0.3, label='Normal')\n",
    "    \n",
    "    # Classified points\n",
    "    scatter = ax3.scatter(df_viz.loc[classified_mask, 'attribute_1'],\n",
    "                         df_viz.loc[classified_mask, 'attribute_2'],\n",
    "                         c=df_viz.loc[classified_mask, 'rank_diff'],\n",
    "                         cmap='RdBu_r', s=80, alpha=0.8,\n",
    "                         edgecolors='black', linewidth=0.5,\n",
    "                         vmin=-100, vmax=100)\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, ax=ax3)\n",
    "    cbar.set_label('Rank Difference (LOF - k-NN)', fontsize=11)\n",
    "    \n",
    "    ax3.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax3.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax3.set_title('Points colored by Rank Difference\\n(Red: LOF>k-NN, Blue: k-NN>LOF)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Confidence vs rank statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    for cls in ['global', 'local']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax4.scatter(df_viz.loc[mask, 'confidence'],\n",
    "                       df_viz.loc[mask, 'rank_diff'],\n",
    "                       c=color_map[cls], s=60, alpha=0.6,\n",
    "                       label=cls.capitalize(), edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax4.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax4.set_xlabel('Classification Confidence', fontsize=12)\n",
    "    ax4.set_ylabel('Rank Difference (LOF - k-NN)', fontsize=12)\n",
    "    ax4.set_title('Confidence vs Rank Difference', fontsize=13, fontweight='bold')\n",
    "    ax4.legend(loc='best', fontsize=10)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"=\"*70)\n",
    "    print(\"RANK DIFFERENCE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for cls in ['global', 'local']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            print(f\"\\n{cls.upper()} outliers:\")\n",
    "            print(f\"  Mean rank difference: {df_viz.loc[mask, 'rank_diff'].mean():7.1f}\")\n",
    "            print(f\"  Median rank diff:     {df_viz.loc[mask, 'rank_diff'].median():7.1f}\")\n",
    "            print(f\"  Std rank diff:        {df_viz.loc[mask, 'rank_diff'].std():7.1f}\")\n",
    "            \n",
    "            # Count how many have LOF rank better than kNN rank\n",
    "            better_lof = (df_viz.loc[mask, 'rank_diff'] < 0).sum()\n",
    "            better_knn = (df_viz.loc[mask, 'rank_diff'] > 0).sum()\n",
    "            print(f\"  LOF rank < k-NN rank: {better_lof}\")\n",
    "            print(f\"  LOF rank > k-NN rank: {better_knn}\")\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "visualize_rank_differences(df_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastLOF Env",
   "language": "python",
   "name": "fastlof-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
