{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/dfki-artificial-3000-unsupervised-ad.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nOutlier label distribution:\")\n",
    "print(df['outlier_label'].value_counts())\n",
    "\n",
    "# Convert outlier_label to binary for plotting\n",
    "df['is_outlier'] = (df['outlier_label'] == 'outlier').astype(int)\n",
    "\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot normal points\n",
    "normal_mask = df['is_outlier'] == 0\n",
    "ax.scatter(df.loc[normal_mask, 'attribute_1'], \n",
    "           df.loc[normal_mask, 'attribute_2'],\n",
    "           c='blue', alpha=0.5, s=20, label='Normal')\n",
    "\n",
    "# Plot outliers\n",
    "outlier_mask = df['is_outlier'] == 1\n",
    "ax.scatter(df.loc[outlier_mask, 'attribute_1'], \n",
    "           df.loc[outlier_mask, 'attribute_2'],\n",
    "           c='red', alpha=0.7, s=30, label='Outlier', marker='x')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title('DFKI Artificial Dataset (3000 samples)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(df[['attribute_1', 'attribute_2']].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df[['attribute_1', 'attribute_2']].values\n",
    "y = df['is_outlier'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "k = 20\n",
    "knn_detector = KNN(n_neighbors=k, contamination=0.01)\n",
    "knn_detector.fit(X_normalized)\n",
    "\n",
    "scores = knn_detector.decision_scores_\n",
    "\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "ranks = np.empty_like(scores, dtype=int)\n",
    "ranks[sorted_indices] = np.arange(1, len(scores) + 1)\n",
    "\n",
    "df['knn_score'] = scores\n",
    "df['knn_rank'] = ranks\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=scores, cmap='viridis', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title(f'Points colored by k-NN Score (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=ranks, cmap='plasma_r', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title(f'Points colored by k-NN Rank', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "cbar2.set_label('Rank (1 = most anomalous)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df[['attribute_1', 'attribute_2']].values\n",
    "y = df['is_outlier'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "k = 20\n",
    "lof_detector = LOF(n_neighbors=k, contamination=0.01)\n",
    "lof_detector.fit(X_normalized)\n",
    "\n",
    "scores = lof_detector.decision_scores_\n",
    "\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "ranks = np.empty_like(scores, dtype=int)\n",
    "ranks[sorted_indices] = np.arange(1, len(scores) + 1)\n",
    "\n",
    "df['lof_score'] = scores\n",
    "df['lof_rank'] = ranks\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=scores, cmap='viridis', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title(f'Points colored by LOF Score (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=ranks, cmap='plasma_r', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title(f'Points colored by LOF Rank', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "cbar2.set_label('Rank (1 = most anomalous)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean combination of k-NN and LOF scores: magnitude + angle\n",
    "\n",
    "knn_scores = df['knn_score'].values\n",
    "lof_scores = df['lof_score'].values\n",
    "\n",
    "mag = np.sqrt(knn_scores**2 + lof_scores**2)\n",
    "angle = np.arctan2(lof_scores, knn_scores)  # LOF vs k-NN\n",
    "\n",
    "# Store for later use if needed\n",
    "df['euc_mag'] = mag\n",
    "df['euc_angle'] = angle\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: magnitude of combined anomaly signal\n",
    "ax1 = axes[0]\n",
    "sc1 = ax1.scatter(\n",
    "    df['attribute_1'], df['attribute_2'],\n",
    "    c=mag, cmap='viridis',\n",
    "    s=30, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    ")\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title('Outlier magnitude: sqrt(LOF^2 + kNN^2)', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(sc1, ax=ax1)\n",
    "cbar1.set_label('Magnitude', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: angle indicating locality vs globality\n",
    "ax2 = axes[1]\n",
    "sc2 = ax2.scatter(\n",
    "    df['attribute_1'], df['attribute_2'],\n",
    "    c=angle, cmap='twilight_shifted',\n",
    "    s=30, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    ")\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title('Locality vs Globality: angle = arctan2(LOF, kNN)', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(sc2, ax=ax2)\n",
    "cbar2.set_label('Angle (radians)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 0\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + p) / (knn_rank + p)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmax = 1\n",
    "vmin = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 20\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + p) / (knn_rank + p)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmax = 1\n",
    "vmin = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"k-NN mean score by label:\")\n",
    "print(df.groupby('is_outlier')['knn_score'].mean())\n",
    "print(\"LOF mean score by label:\")\n",
    "print(df.groupby('is_outlier')['lof_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def analyze_ensemble_globality(df, X_normalized, k_list=[3, 4, 5, 6, 7], contamination=0.05):\n",
    "    \"\"\"\n",
    "    Computes Globality Index by averaging distances to centroids over multiple k values.\n",
    "    Filters top anomalies using existing LOF scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Running Ensemble Globality Analysis ---\")\n",
    "    print(f\"Averaging cluster structures for k = {k_list}\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. ENSEMBLE DISTANCE CALCULATION\n",
    "    # ==========================================\n",
    "    n_samples = X_normalized.shape[0]\n",
    "    cumulative_dists = np.zeros(n_samples)\n",
    "    \n",
    "    # Iterate through each k in the list\n",
    "    for k in k_list:\n",
    "        # Fit KMeans\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto').fit(X_normalized)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Get min distance to ANY center for this specific k\n",
    "        dists = pairwise_distances(X_normalized, centers).min(axis=1)\n",
    "        \n",
    "        # Add to cumulative sum\n",
    "        cumulative_dists += dists\n",
    "\n",
    "    # Average the distances\n",
    "    avg_dists_to_centers = cumulative_dists / len(k_list)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 2. FILTER CANDIDATES (Top C% by LOF)\n",
    "    # ==========================================\n",
    "    # We assume 'lof_score' already exists in df from previous steps\n",
    "    if 'lof_score' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'lof_score' column.\")\n",
    "        \n",
    "    threshold = df['lof_score'].quantile(1 - contamination)\n",
    "    candidate_mask = df['lof_score'] > threshold\n",
    "    \n",
    "    # Extract distances only for the candidates\n",
    "    candidate_dists = avg_dists_to_centers[candidate_mask]\n",
    "    candidate_indices = df.index[candidate_mask]\n",
    "    \n",
    "    # ==========================================\n",
    "    # 3. COMPUTE FINAL INDEX (Standardize Subset)\n",
    "    # ==========================================\n",
    "    # Normalize the average distances of the candidates to 0-1 for coloring\n",
    "    scaler_subset = MinMaxScaler()\n",
    "    globality_index = scaler_subset.fit_transform(candidate_dists.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Store in DF\n",
    "    col_name = 'ensemble_globality_index'\n",
    "    df[col_name] = np.nan\n",
    "    df.loc[candidate_indices, col_name] = globality_index\n",
    "    \n",
    "    # ==========================================\n",
    "    # 4. VISUALIZATION\n",
    "    # ==========================================\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # A. Plot Background (Normal Points)\n",
    "    ax.scatter(df.loc[~candidate_mask, 'attribute_1'], \n",
    "               df.loc[~candidate_mask, 'attribute_2'],\n",
    "               c='gainsboro', s=20, alpha=0.4, label='Normal Data')\n",
    "\n",
    "    # B. Plot Candidates (Colored by Ensemble Globality)\n",
    "    scatter = ax.scatter(df.loc[candidate_mask, 'attribute_1'], \n",
    "                         df.loc[candidate_mask, 'attribute_2'], \n",
    "                         c=globality_index, \n",
    "                         cmap='plasma', # plasma is great for intensity\n",
    "                         s=60, alpha=0.9, edgecolors='black', linewidth=0.5,\n",
    "                         label=f'Top {int(contamination*100)}% Anomalies')\n",
    "\n",
    "    # Formatting\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(f'Ensemble Globality (Avg Dist to Centers, k={k_list})', fontsize=11)\n",
    "    cbar.set_ticks([0, 0.5, 1])\n",
    "    cbar.set_ticklabels(['Local (Sparse Inlier)', 'Mixed', 'Global (Isolated)'])\n",
    "\n",
    "    ax.set_title(f'Ensemble Globality Map (Averaged over k={k_list})\\n'\n",
    "                 f'Showing top {int(contamination*100)}% LOF candidates', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Attribute 1')\n",
    "    ax.set_ylabel('Attribute 2')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# HOW TO RUN IT\n",
    "# ==========================================\n",
    "\n",
    "# We average over k=3, 4, 5, 6, 7 to account for structural ambiguity\n",
    "# This makes the \"Global\" score much more scientifically robust\n",
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[5], \n",
    "    contamination=0.05\n",
    ")\n",
    "\n",
    "# Check the top results\n",
    "print(\"\\nTop 5 Global Outliers (Most Isolated across all k):\")\n",
    "cols = ['attribute_1', 'attribute_2', 'ensemble_globality_index']\n",
    "print(df.dropna(subset=['ensemble_globality_index']).nlargest(5, 'ensemble_globality_index')[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[3, 4, 5, 6, 7], \n",
    "    contamination=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[4,5,6,7,8,9,10], \n",
    "    contamination=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[3,4,5,6,7], \n",
    "    contamination=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 20\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + knn_rank) / 2* (lof_rank)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmin = ratio_min\n",
    "vmax = ratio_max\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastLOF Env",
   "language": "python",
   "name": "fastlof-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
