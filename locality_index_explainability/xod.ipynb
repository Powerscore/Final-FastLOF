{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/dfki-artificial-3000-unsupervised-ad.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nOutlier label distribution:\")\n",
    "print(df['outlier_label'].value_counts())\n",
    "\n",
    "# Convert outlier_label to binary for plotting\n",
    "df['is_outlier'] = (df['outlier_label'] == 'outlier').astype(int)\n",
    "\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot normal points\n",
    "normal_mask = df['is_outlier'] == 0\n",
    "ax.scatter(df.loc[normal_mask, 'attribute_1'], \n",
    "           df.loc[normal_mask, 'attribute_2'],\n",
    "           c='blue', alpha=0.5, s=20, label='Normal')\n",
    "\n",
    "# Plot outliers\n",
    "outlier_mask = df['is_outlier'] == 1\n",
    "ax.scatter(df.loc[outlier_mask, 'attribute_1'], \n",
    "           df.loc[outlier_mask, 'attribute_2'],\n",
    "           c='red', alpha=0.7, s=30, label='Outlier', marker='x')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title('DFKI Artificial Dataset (3000 samples)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(df[['attribute_1', 'attribute_2']].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df[['attribute_1', 'attribute_2']].values\n",
    "y = df['is_outlier'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "k = 20\n",
    "knn_detector = KNN(n_neighbors=k, contamination=0.01)\n",
    "knn_detector.fit(X_normalized)\n",
    "\n",
    "scores = knn_detector.decision_scores_\n",
    "\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "ranks = np.empty_like(scores, dtype=int)\n",
    "ranks[sorted_indices] = np.arange(1, len(scores) + 1)\n",
    "\n",
    "df['knn_score'] = scores\n",
    "df['knn_rank'] = ranks\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=scores, cmap='viridis', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title(f'Points colored by k-NN Score (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=ranks, cmap='plasma_r', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title(f'Points colored by k-NN Rank', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "cbar2.set_label('Rank (1 = most anomalous)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df[['attribute_1', 'attribute_2']].values\n",
    "y = df['is_outlier'].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "k = 20\n",
    "lof_detector = LOF(n_neighbors=k, contamination=0.01)\n",
    "lof_detector.fit(X_normalized)\n",
    "\n",
    "scores = lof_detector.decision_scores_\n",
    "\n",
    "sorted_indices = np.argsort(scores)[::-1]\n",
    "ranks = np.empty_like(scores, dtype=int)\n",
    "ranks[sorted_indices] = np.arange(1, len(scores) + 1)\n",
    "\n",
    "df['lof_score'] = scores\n",
    "df['lof_rank'] = ranks\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=scores, cmap='viridis', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title(f'Points colored by LOF Score (k={k})', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
    "cbar1.set_label('Anomaly Score', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(df['attribute_1'], df['attribute_2'], \n",
    "                       c=ranks, cmap='plasma_r', \n",
    "                       s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title(f'Points colored by LOF Rank', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
    "cbar2.set_label('Rank (1 = most anomalous)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean combination of k-NN and LOF scores: magnitude + angle\n",
    "\n",
    "knn_scores = df['knn_score'].values\n",
    "lof_scores = df['lof_score'].values\n",
    "\n",
    "mag = np.sqrt(knn_scores**2 + lof_scores**2)\n",
    "angle = np.arctan2(lof_scores, knn_scores)  # LOF vs k-NN\n",
    "\n",
    "# Store for later use if needed\n",
    "df['euc_mag'] = mag\n",
    "df['euc_angle'] = angle\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: magnitude of combined anomaly signal\n",
    "ax1 = axes[0]\n",
    "sc1 = ax1.scatter(\n",
    "    df['attribute_1'], df['attribute_2'],\n",
    "    c=mag, cmap='viridis',\n",
    "    s=30, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    ")\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title('Outlier magnitude: sqrt(LOF^2 + kNN^2)', fontsize=13, fontweight='bold')\n",
    "cbar1 = plt.colorbar(sc1, ax=ax1)\n",
    "cbar1.set_label('Magnitude', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: angle indicating locality vs globality\n",
    "ax2 = axes[1]\n",
    "sc2 = ax2.scatter(\n",
    "    df['attribute_1'], df['attribute_2'],\n",
    "    c=angle, cmap='twilight_shifted',\n",
    "    s=30, alpha=0.7, edgecolors='black', linewidth=0.5,\n",
    ")\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title('Locality vs Globality: angle = arctan2(LOF, kNN)', fontsize=13, fontweight='bold')\n",
    "cbar2 = plt.colorbar(sc2, ax=ax2)\n",
    "cbar2.set_label('Angle (radians)', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 0\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + p) / (knn_rank + p)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmax = 1\n",
    "vmin = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 20\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + p) / (knn_rank + p)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmax = 1\n",
    "vmin = 0.6\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"k-NN mean score by label:\")\n",
    "print(df.groupby('is_outlier')['knn_score'].mean())\n",
    "print(\"LOF mean score by label:\")\n",
    "print(df.groupby('is_outlier')['lof_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def analyze_ensemble_globality(df, X_normalized, k_list=[3, 4, 5, 6, 7], contamination=0.05):\n",
    "    \"\"\"\n",
    "    Computes Globality Index by averaging distances to centroids over multiple k values.\n",
    "    Filters top anomalies using existing LOF scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Running Ensemble Globality Analysis ---\")\n",
    "    print(f\"Averaging cluster structures for k = {k_list}\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. ENSEMBLE DISTANCE CALCULATION\n",
    "    # ==========================================\n",
    "    n_samples = X_normalized.shape[0]\n",
    "    cumulative_dists = np.zeros(n_samples)\n",
    "    \n",
    "    # Iterate through each k in the list\n",
    "    for k in k_list:\n",
    "        # Fit KMeans\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto').fit(X_normalized)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Get min distance to ANY center for this specific k\n",
    "        dists = pairwise_distances(X_normalized, centers).min(axis=1)\n",
    "        \n",
    "        # Add to cumulative sum\n",
    "        cumulative_dists += dists\n",
    "\n",
    "    # Average the distances\n",
    "    avg_dists_to_centers = cumulative_dists / len(k_list)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 2. FILTER CANDIDATES (Top C% by LOF)\n",
    "    # ==========================================\n",
    "    # We assume 'lof_score' already exists in df from previous steps\n",
    "    if 'lof_score' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'lof_score' column.\")\n",
    "        \n",
    "    threshold = df['lof_score'].quantile(1 - contamination)\n",
    "    candidate_mask = df['lof_score'] > threshold\n",
    "    \n",
    "    # Extract distances only for the candidates\n",
    "    candidate_dists = avg_dists_to_centers[candidate_mask]\n",
    "    candidate_indices = df.index[candidate_mask]\n",
    "    \n",
    "    # ==========================================\n",
    "    # 3. COMPUTE FINAL INDEX (Standardize Subset)\n",
    "    # ==========================================\n",
    "    # Normalize the average distances of the candidates to 0-1 for coloring\n",
    "    scaler_subset = MinMaxScaler()\n",
    "    globality_index = scaler_subset.fit_transform(candidate_dists.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Store in DF\n",
    "    col_name = 'ensemble_globality_index'\n",
    "    df[col_name] = np.nan\n",
    "    df.loc[candidate_indices, col_name] = globality_index\n",
    "    \n",
    "    # ==========================================\n",
    "    # 4. VISUALIZATION\n",
    "    # ==========================================\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # A. Plot Background (Normal Points)\n",
    "    ax.scatter(df.loc[~candidate_mask, 'attribute_1'], \n",
    "               df.loc[~candidate_mask, 'attribute_2'],\n",
    "               c='gainsboro', s=20, alpha=0.4, label='Normal Data')\n",
    "\n",
    "    # B. Plot Candidates (Colored by Ensemble Globality)\n",
    "    scatter = ax.scatter(df.loc[candidate_mask, 'attribute_1'], \n",
    "                         df.loc[candidate_mask, 'attribute_2'], \n",
    "                         c=globality_index, \n",
    "                         cmap='plasma', # plasma is great for intensity\n",
    "                         s=60, alpha=0.9, edgecolors='black', linewidth=0.5,\n",
    "                         label=f'Top {int(contamination*100)}% Anomalies')\n",
    "\n",
    "    # Formatting\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(f'Ensemble Globality (Avg Dist to Centers, k={k_list})', fontsize=11)\n",
    "    cbar.set_ticks([0, 0.5, 1])\n",
    "    cbar.set_ticklabels(['Local (Sparse Inlier)', 'Mixed', 'Global (Isolated)'])\n",
    "\n",
    "    ax.set_title(f'Ensemble Globality Map (Averaged over k={k_list})\\n'\n",
    "                 f'Showing top {int(contamination*100)}% LOF candidates', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Attribute 1')\n",
    "    ax.set_ylabel('Attribute 2')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# HOW TO RUN IT\n",
    "# ==========================================\n",
    "\n",
    "# We average over k=3, 4, 5, 6, 7 to account for structural ambiguity\n",
    "# This makes the \"Global\" score much more scientifically robust\n",
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[5], \n",
    "    contamination=0.05\n",
    ")\n",
    "\n",
    "# Check the top results\n",
    "print(\"\\nTop 5 Global Outliers (Most Isolated across all k):\")\n",
    "cols = ['attribute_1', 'attribute_2', 'ensemble_globality_index']\n",
    "print(df.dropna(subset=['ensemble_globality_index']).nlargest(5, 'ensemble_globality_index')[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[3, 4, 5, 6, 7], \n",
    "    contamination=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[4,5,6,7,8,9,10], \n",
    "    contamination=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_ensemble_globality(\n",
    "    df, \n",
    "    X_normalized, \n",
    "    k_list=[3,4,5,6,7], \n",
    "    contamination=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "p = 20\n",
    "top_knn_indices = df.nsmallest(c, 'knn_rank').index.values\n",
    "top_lof_indices = df.nsmallest(c, 'lof_rank').index.values\n",
    "\n",
    "all_top_indices = np.unique(np.concatenate([top_knn_indices, top_lof_indices]))\n",
    "\n",
    "ratio_values = np.full(len(df), np.nan)\n",
    "for idx in all_top_indices:\n",
    "    knn_rank = df.loc[idx, 'knn_rank']\n",
    "    lof_rank = df.loc[idx, 'lof_rank']\n",
    "    ratio = (lof_rank + knn_rank) / 2* (lof_rank)\n",
    "    ratio_values[idx] = ratio\n",
    "\n",
    "mask_top = ~np.isnan(ratio_values)\n",
    "mask_other = np.isnan(ratio_values)\n",
    "\n",
    "ratio_min = ratio_values[mask_top].min()\n",
    "ratio_max = ratio_values[mask_top].max()\n",
    "ratio_mean = ratio_values[mask_top].mean()\n",
    "\n",
    "vmin = max(0.1, ratio_min * 0.9)\n",
    "vmax = min(ratio_max * 1.1, ratio_max + 0.5)\n",
    "vmin = ratio_min\n",
    "vmax = ratio_max\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter_other = ax.scatter(df.loc[mask_other, 'attribute_1'], \n",
    "                          df.loc[mask_other, 'attribute_2'],\n",
    "                          c='black', s=20, alpha=0.3, label='Other points')\n",
    "\n",
    "scatter_top = ax.scatter(df.loc[mask_top, 'attribute_1'], \n",
    "                         df.loc[mask_top, 'attribute_2'],\n",
    "                         c=ratio_values[mask_top], cmap='RdYlGn', \n",
    "                         s=50, alpha=0.8, edgecolors='black', linewidth=0.5,\n",
    "                         vmin=vmin, vmax=vmax, label='Top c points')\n",
    "\n",
    "ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax.set_title(f'Global vs Local Outliers (c={c})\\nRatio = (LOF rank + {p}) / (k-NN rank + {p})', \n",
    "             fontsize=13, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter_top, ax=ax)\n",
    "cbar.set_label('Ratio (1 = global outlier, 0 = local outlier)', fontsize=11)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top {c} points by k-NN rank: {len(top_knn_indices)}\")\n",
    "print(f\"Top {c} points by LOF rank: {len(top_lof_indices)}\")\n",
    "print(f\"Total unique top points: {len(all_top_indices)}\")\n",
    "print(f\"\\nRatio statistics for top points:\")\n",
    "print(f\"  Mean: {ratio_values[mask_top].mean():.4f}\")\n",
    "print(f\"  Min: {ratio_values[mask_top].min():.4f}\")\n",
    "print(f\"  Max: {ratio_values[mask_top].max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Majority Voting Algorithm for Local vs Global Outlier Classification\n",
    "\n",
    "**Key Idea:**\n",
    "- If a point is in the top-c anomalies for **both k-NN and LOF** → vote for **Global**\n",
    "- If a point is in the top-c anomalies for **LOF only** (not k-NN) → vote for **Local**\n",
    "- Repeat for multiple c thresholds and use **majority voting** to classify each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_classifier(\n",
    "    df,\n",
    "    c_values,\n",
    "    knn_rank_col='knn_rank',\n",
    "    lof_rank_col='lof_rank',\n",
    "    assume_smaller_is_more_anomalous=True,\n",
    "    weight_by_inverse_c=False,\n",
    "    min_votes_to_classify=1,\n",
    "    handle_knn_only_as='knn_only'  # options: 'ignore', 'global', 'knn_only'\n",
    "):\n",
    "    \"\"\"\n",
    "    Ensemble top-c memberships across multiple c thresholds to label points as:\n",
    "      - 'global'  : both methods agree (more global votes than local)\n",
    "      - 'local'   : LOF-only signal dominates\n",
    "      - 'knn_only': (optional) k-NN-only signal dominates (if handle_knn_only_as=='knn_only')\n",
    "      - 'tie'     : equal non-zero votes\n",
    "      - 'normal'  : no votes or below min_votes_to_classify\n",
    "\n",
    "    IMPORTANT:\n",
    "      - This implementation assumes smaller rank == more anomalous (rank=1 is top). \n",
    "        If you use scores where larger is more anomalous, set `assume_smaller_is_more_anomalous=False`\n",
    "        and adjust how top-c are selected (use nlargest).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "\n",
    "    # safe vote containers indexed by df.index\n",
    "    votes_global = pd.Series(0.0, index=df.index)\n",
    "    votes_local = pd.Series(0.0, index=df.index)\n",
    "    votes_knn_only = pd.Series(0.0, index=df.index)\n",
    "\n",
    "    for c in c_values:\n",
    "        if c <= 0:\n",
    "            continue\n",
    "        c = min(c, n)\n",
    "        weight = (1.0 / c) if weight_by_inverse_c else 1.0\n",
    "\n",
    "        if assume_smaller_is_more_anomalous:\n",
    "            top_knn_idx = df.nsmallest(c, knn_rank_col).index\n",
    "            top_lof_idx = df.nsmallest(c, lof_rank_col).index\n",
    "        else:\n",
    "            top_knn_idx = df.nlargest(c, knn_rank_col).index\n",
    "            top_lof_idx = df.nlargest(c, lof_rank_col).index\n",
    "\n",
    "        knn_mask = df.index.isin(top_knn_idx)\n",
    "        lof_mask = df.index.isin(top_lof_idx)\n",
    "\n",
    "        both_mask = knn_mask & lof_mask\n",
    "        only_lof_mask = lof_mask & ~knn_mask\n",
    "        only_knn_mask = knn_mask & ~lof_mask\n",
    "\n",
    "        votes_global.loc[both_mask] += weight\n",
    "        votes_local.loc[only_lof_mask] += weight\n",
    "\n",
    "        if handle_knn_only_as == 'global':\n",
    "            votes_global.loc[only_knn_mask] += weight\n",
    "        elif handle_knn_only_as == 'knn_only':\n",
    "            votes_knn_only.loc[only_knn_mask] += weight\n",
    "        # else: ignore k-NN-only\n",
    "\n",
    "    df['votes_global'] = votes_global\n",
    "    df['votes_local'] = votes_local\n",
    "    if handle_knn_only_as == 'knn_only':\n",
    "        df['votes_knn_only'] = votes_knn_only\n",
    "    df['total_votes'] = df['votes_global'] + df['votes_local'] + (df.get('votes_knn_only', 0))\n",
    "\n",
    "    # Classification rules\n",
    "    def classify_row(row):\n",
    "        g = row['votes_global']\n",
    "        l = row['votes_local']\n",
    "        k = row.get('votes_knn_only', 0)\n",
    "        total = g + l + k\n",
    "        if total < min_votes_to_classify:\n",
    "            return 'normal'\n",
    "        # prefer global if strictly higher\n",
    "        if g > l and g > k:\n",
    "            return 'global'\n",
    "        if l > g and l > k:\n",
    "            return 'local'\n",
    "        if k > g and k > l:\n",
    "            return 'knn_only'\n",
    "        if (g == l == 0) and k > 0:\n",
    "            return 'knn_only' if handle_knn_only_as == 'knn_only' else 'normal'\n",
    "        if g == l and g > 0 and g > k:\n",
    "            return 'tie'\n",
    "        # fallback\n",
    "        return 'normal'\n",
    "\n",
    "    df['classification'] = df.apply(classify_row, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Visualization of Results\n",
    "# ============================\n",
    "\n",
    "# Check if classification column exists, if not run the classifier first\n",
    "if 'classification' not in df.columns:\n",
    "    print(\"Classification column not found. Running majority voting classifier...\")\n",
    "    # Ensure we have the required rank columns\n",
    "    if 'knn_rank' not in df.columns or 'lof_rank' not in df.columns:\n",
    "        raise ValueError(\"Missing required columns: 'knn_rank' and 'lof_rank' must exist. Please run k-NN and LOF detection first.\")\n",
    "    \n",
    "    # Define threshold values for majority voting\n",
    "    c_values = [5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "    \n",
    "    # Run the classifier\n",
    "    df = majority_voting_classifier(df, c_values)\n",
    "    print(f\"Classification complete. Classified {len(df[df['classification'] != 'normal'])} anomalies.\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Consistent color map for categories\n",
    "color_map = {\n",
    "    'normal': 'lightgray',\n",
    "    'global': 'red',\n",
    "    'local': 'blue',\n",
    "    'tie': 'purple'\n",
    "}\n",
    "\n",
    "# ---- PLOT 1: Classification Scatter ----\n",
    "ax1 = axes[0]\n",
    "\n",
    "for cls in ['global', 'local', 'tie', 'normal']:\n",
    "    mask = df['classification'] == cls\n",
    "    if mask.any():\n",
    "        ax1.scatter(\n",
    "            df.loc[mask, 'attribute_1'],\n",
    "            df.loc[mask, 'attribute_2'],\n",
    "            c=color_map[cls],\n",
    "            s=90 if cls in ['global', 'local'] else 35,\n",
    "            alpha=0.75 if cls in ['global', 'local'] else 0.35,\n",
    "            label=f\"{cls.capitalize()} ({mask.sum()})\",\n",
    "            edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "ax1.set_title(\n",
    "    \"Local vs Global Outlier Classification (Majority Voting)\",\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "ax1.set_xlabel(\"Attribute 1\", fontsize=12)\n",
    "ax1.set_ylabel(\"Attribute 2\", fontsize=12)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "\n",
    "# ---- PLOT 2: Total Votes Heat Scatter ----\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Normal/tie as background\n",
    "background_mask = df['classification'].isin(['normal', 'tie'])\n",
    "\n",
    "ax2.scatter(\n",
    "    df.loc[background_mask, 'attribute_1'],\n",
    "    df.loc[background_mask, 'attribute_2'],\n",
    "    c='lightgray',\n",
    "    s=25,\n",
    "    alpha=0.25,\n",
    "    label='Normal/Tie'\n",
    ")\n",
    "\n",
    "# Only anomalies for heatmap coloring\n",
    "anom_mask = df['classification'].isin(['global', 'local'])\n",
    "\n",
    "heat = ax2.scatter(\n",
    "    df.loc[anom_mask, 'attribute_1'],\n",
    "    df.loc[anom_mask, 'attribute_2'],\n",
    "    c=df.loc[anom_mask, 'total_votes'],\n",
    "    cmap='viridis',\n",
    "    s=80,\n",
    "    alpha=0.85,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "ax2.set_title(\n",
    "    \"Total Votes per Anomaly (Strength of Evidence)\",\n",
    "    fontsize=14, fontweight='bold'\n",
    ")\n",
    "ax2.set_xlabel(\"Attribute 1\", fontsize=12)\n",
    "ax2.set_ylabel(\"Attribute 2\", fontsize=12)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "cbar = plt.colorbar(heat, ax=ax2)\n",
    "cbar.set_label(\"Total Votes\", fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ==========================================\n",
    "# FORMULA IMPLEMENTATIONS\n",
    "# ==========================================\n",
    "\n",
    "def compute_formulas(df, knn_rank_col='knn_rank', lof_rank_col='lof_rank'):\n",
    "    \"\"\"\n",
    "    Compute 4 different rank-based globality formulas.\n",
    "    All formulas output values where:\n",
    "      - Positive → Global outlier (kNN ranks it worse)\n",
    "      - Negative → Local outlier (LOF ranks it worse)\n",
    "      - Near 0 → Ambiguous\n",
    "    \"\"\"\n",
    "    knn_ranks = df[knn_rank_col].values\n",
    "    lof_ranks = df[lof_rank_col].values\n",
    "    n = len(df)\n",
    "    \n",
    "    # Formula 1: Grounded Rank Difference (YOUR TARGET)\n",
    "    # Most stable, grounded by total rank magnitude\n",
    "    df['f1_grounded'] = (lof_ranks - knn_ranks) / (lof_ranks + knn_ranks + 1)\n",
    "    \n",
    "    # Formula 2: Simple Normalized Difference\n",
    "    # Normalized by the larger rank (more sensitive to extremes)\n",
    "    df['f2_normalized'] = (lof_ranks - knn_ranks) / np.maximum(lof_ranks, knn_ranks)\n",
    "    \n",
    "    # Formula 3: Percentile-Based Difference\n",
    "    # Distribution-aware, accounts for dataset size\n",
    "    lof_percentile = lof_ranks / n\n",
    "    knn_percentile = knn_ranks / n\n",
    "    df['f3_percentile'] = lof_percentile - knn_percentile\n",
    "    \n",
    "    # Formula 4: Average-Grounded Difference\n",
    "    # Similar to F1 but uses average instead of sum\n",
    "    avg_rank = (lof_ranks + knn_ranks) / 2\n",
    "    df['f4_avg_grounded'] = (lof_ranks - knn_ranks) / (avg_rank + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# CLASSIFICATION FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def classify_by_formula(df, formula_col, threshold_global=0.1, threshold_local=-0.1):\n",
    "    \"\"\"\n",
    "    Classify points based on formula score:\n",
    "      - score > threshold_global → 'global'\n",
    "      - score < threshold_local → 'local'\n",
    "      - else → 'normal'\n",
    "    \"\"\"\n",
    "    classifications = []\n",
    "    for score in df[formula_col]:\n",
    "        if score > threshold_global:\n",
    "            classifications.append('global')\n",
    "        elif score < threshold_local:\n",
    "            classifications.append('local')\n",
    "        else:\n",
    "            classifications.append('normal')\n",
    "    return classifications\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION AGAINST GROUND TRUTH\n",
    "# ==========================================\n",
    "\n",
    "def evaluate_method(df, pred_col, true_col='is_outlier'):\n",
    "    \"\"\"\n",
    "    Evaluate predictions against ground truth.\n",
    "    Treats 'global' and 'local' as outliers (1), 'normal' as inliers (0).\n",
    "    \"\"\"\n",
    "    # Convert classifications to binary\n",
    "    y_true = df[true_col].values\n",
    "    y_pred = df[pred_col].apply(lambda x: 1 if x in ['global', 'local'] else 0).values\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Count classifications\n",
    "    n_global = (df[pred_col] == 'global').sum()\n",
    "    n_local = (df[pred_col] == 'local').sum()\n",
    "    n_normal = (df[pred_col] == 'normal').sum()\n",
    "    \n",
    "    # Ground truth breakdown for detected outliers\n",
    "    detected_outliers = df[df[pred_col].isin(['global', 'local'])]\n",
    "    true_positives = detected_outliers[detected_outliers[true_col] == 1]\n",
    "    false_positives = detected_outliers[detected_outliers[true_col] == 0]\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'n_global': n_global,\n",
    "        'n_local': n_local,\n",
    "        'n_normal': n_normal,\n",
    "        'true_positives': len(true_positives),\n",
    "        'false_positives': len(false_positives),\n",
    "        'pct_true_outliers_as_global': (true_positives[pred_col] == 'global').sum() / max(1, len(true_positives)) * 100\n",
    "    }\n",
    "\n",
    "# ==========================================\n",
    "# MAIN TESTING FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def test_all_formulas(df):\n",
    "    \"\"\"\n",
    "    Test all formulas and compare to majority voting.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"TESTING RANK DIFFERENCE FORMULAS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Compute all formulas\n",
    "    df = compute_formulas(df)\n",
    "    \n",
    "    # Test different thresholds for each formula\n",
    "    formulas = {\n",
    "        'F1: Grounded': ('f1_grounded', 0.15, -0.15),\n",
    "        'F2: Normalized': ('f2_normalized', 0.15, -0.15),\n",
    "        'F3: Percentile': ('f3_percentile', 0.05, -0.05),\n",
    "        'F4: Avg Grounded': ('f4_avg_grounded', 0.20, -0.20)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, (col, thresh_g, thresh_l) in formulas.items():\n",
    "        class_col = f'{col}_class'\n",
    "        df[class_col] = classify_by_formula(df, col, thresh_g, thresh_l)\n",
    "        metrics = evaluate_method(df, class_col)\n",
    "        results[name] = metrics\n",
    "        \n",
    "        print(f\"\\n{name} (thresholds: >{thresh_g:.2f} global, <{thresh_l:.2f} local)\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.3f}\")\n",
    "        print(f\"  Precision: {metrics['precision']:.3f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.3f}\")\n",
    "        print(f\"  F1-Score: {metrics['f1_score']:.3f}\")\n",
    "        print(f\"  Classified: {metrics['n_global']} global, {metrics['n_local']} local, {metrics['n_normal']} normal\")\n",
    "        print(f\"  True outliers as global: {metrics['pct_true_outliers_as_global']:.1f}%\")\n",
    "    \n",
    "    # Compare to majority voting if it exists\n",
    "    if 'classification' in df.columns:\n",
    "        print(f\"\\nMAJORITY VOTING (for comparison)\")\n",
    "        mv_metrics = evaluate_method(df, 'classification')\n",
    "        results['Majority Voting'] = mv_metrics\n",
    "        print(f\"  Accuracy: {mv_metrics['accuracy']:.3f}\")\n",
    "        print(f\"  Precision: {mv_metrics['precision']:.3f}\")\n",
    "        print(f\"  Recall: {mv_metrics['recall']:.3f}\")\n",
    "        print(f\"  F1-Score: {mv_metrics['f1_score']:.3f}\")\n",
    "        print(f\"  Classified: {mv_metrics['n_global']} global, {mv_metrics['n_local']} local, {mv_metrics['n_normal']} normal\")\n",
    "        print(f\"  True outliers as global: {mv_metrics['pct_true_outliers_as_global']:.1f}%\")\n",
    "    \n",
    "    return df, results\n",
    "\n",
    "# ==========================================\n",
    "# VISUALIZATION: COMPARE ALL METHODS\n",
    "# ==========================================\n",
    "\n",
    "def visualize_all_methods(df):\n",
    "    \"\"\"\n",
    "    Create a comprehensive comparison visualization.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    color_map = {\n",
    "        'normal': 'lightgray',\n",
    "        'global': 'red',\n",
    "        'local': 'blue',\n",
    "        'tie': 'purple'\n",
    "    }\n",
    "    \n",
    "    methods = [\n",
    "        ('f1_grounded_class', 'F1: Grounded Rank Diff'),\n",
    "        ('f2_normalized_class', 'F2: Normalized Diff'),\n",
    "        ('f3_percentile_class', 'F3: Percentile Diff'),\n",
    "        ('f4_avg_grounded_class', 'F4: Avg Grounded'),\n",
    "        ('classification', 'Majority Voting'),\n",
    "        ('is_outlier', 'Ground Truth (Labels)')\n",
    "    ]\n",
    "    \n",
    "    for idx, (col, title) in enumerate(methods):\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        ax = axes[idx // 3, idx % 3]\n",
    "        \n",
    "        # Handle ground truth differently (binary)\n",
    "        if col == 'is_outlier':\n",
    "            for val, color, label in [(0, 'lightgray', 'Normal'), (1, 'red', 'Outlier')]:\n",
    "                mask = df[col] == val\n",
    "                ax.scatter(df.loc[mask, 'attribute_1'], df.loc[mask, 'attribute_2'],\n",
    "                          c=color, s=60 if val == 1 else 25, alpha=0.7 if val == 1 else 0.3,\n",
    "                          label=f\"{label} ({mask.sum()})\", edgecolors='black' if val == 1 else 'none',\n",
    "                          linewidth=0.5)\n",
    "        else:\n",
    "            for cls in ['global', 'local', 'tie', 'normal']:\n",
    "                mask = df[col] == cls\n",
    "                if mask.any():\n",
    "                    ax.scatter(df.loc[mask, 'attribute_1'], df.loc[mask, 'attribute_2'],\n",
    "                              c=color_map[cls], s=70 if cls in ['global', 'local'] else 30,\n",
    "                              alpha=0.75 if cls in ['global', 'local'] else 0.3,\n",
    "                              label=f\"{cls.capitalize()} ({mask.sum()})\",\n",
    "                              edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "                              linewidth=0.5)\n",
    "        \n",
    "        ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "        ax.set_xlabel('Attribute 1', fontsize=10)\n",
    "        ax.set_ylabel('Attribute 2', fontsize=10)\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# FORMULA DISTRIBUTION VISUALIZATION\n",
    "# ==========================================\n",
    "\n",
    "def visualize_formula_distributions(df):\n",
    "    \"\"\"\n",
    "    Show the distribution of formula scores for true outliers vs normal points.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    formulas = [\n",
    "        ('f1_grounded', 'F1: Grounded Rank Difference'),\n",
    "        ('f2_normalized', 'F2: Normalized Difference'),\n",
    "        ('f3_percentile', 'F3: Percentile Difference'),\n",
    "        ('f4_avg_grounded', 'F4: Avg Grounded Difference')\n",
    "    ]\n",
    "    \n",
    "    for idx, (col, title) in enumerate(formulas):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        \n",
    "        # Separate by ground truth\n",
    "        normal_scores = df[df['is_outlier'] == 0][col]\n",
    "        outlier_scores = df[df['is_outlier'] == 1][col]\n",
    "        \n",
    "        # Plot histograms\n",
    "        ax.hist(normal_scores, bins=50, alpha=0.6, color='blue', label=f'Normal (n={len(normal_scores)})')\n",
    "        ax.hist(outlier_scores, bins=30, alpha=0.7, color='red', label=f'Outliers (n={len(outlier_scores)})')\n",
    "        \n",
    "        # Add vertical lines for mean\n",
    "        ax.axvline(normal_scores.mean(), color='blue', linestyle='--', linewidth=2, label=f'Normal mean: {normal_scores.mean():.3f}')\n",
    "        ax.axvline(outlier_scores.mean(), color='red', linestyle='--', linewidth=2, label=f'Outlier mean: {outlier_scores.mean():.3f}')\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Formula Score', fontsize=10)\n",
    "        ax.set_ylabel('Frequency', fontsize=10)\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# RESULTS COMPARISON TABLE\n",
    "# ==========================================\n",
    "\n",
    "def print_results_table(results):\n",
    "    \"\"\"\n",
    "    Print a clean comparison table of all methods.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"COMPREHENSIVE RESULTS COMPARISON\")\n",
    "    print(\"=\"*90)\n",
    "    print(f\"{'Method':<20} {'Accuracy':<10} {'Precision':<11} {'Recall':<10} {'F1':<10} {'% True as Global':<15}\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{name:<20} {metrics['accuracy']:<10.3f} {metrics['precision']:<11.3f} \"\n",
    "              f\"{metrics['recall']:<10.3f} {metrics['f1_score']:<10.3f} \"\n",
    "              f\"{metrics['pct_true_outliers_as_global']:<15.1f}\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "# ==========================================\n",
    "# HOW TO USE THIS CODE\n",
    "# ==========================================\n",
    "\"\"\"\n",
    "# Assuming you have df with 'knn_rank', 'lof_rank', and 'is_outlier' columns:\n",
    "\n",
    "# 1. Test all formulas\n",
    "df, results = test_all_formulas(df)\n",
    "\n",
    "# 2. Visualize all methods side-by-side\n",
    "visualize_all_methods(df)\n",
    "\n",
    "# 3. See formula distributions\n",
    "visualize_formula_distributions(df)\n",
    "\n",
    "# 4. Print comparison table\n",
    "print_results_table(results)\n",
    "\n",
    "# 5. Examine specific outliers\n",
    "print(\"\\nTop 10 outliers by Grounded Formula:\")\n",
    "print(df.nlargest(10, 'f1_grounded')[['attribute_1', 'attribute_2', 'f1_grounded', \n",
    "                                       'knn_rank', 'lof_rank', 'is_outlier']])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all formulas and get results\n",
    "df, results = test_all_formulas(df)\n",
    "\n",
    "# Visualize everything side-by-side\n",
    "visualize_all_methods(df)\n",
    "\n",
    "# See how formulas separate outliers vs normal\n",
    "visualize_formula_distributions(df)\n",
    "\n",
    "# Print comparison table\n",
    "print_results_table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# CANDIDATE FILTERING\n",
    "# ==========================================\n",
    "\n",
    "def get_candidate_mask(df, c=50, knn_rank_col='knn_rank', lof_rank_col='lof_rank'):\n",
    "    \"\"\"\n",
    "    Get union of top-c candidates from both kNN and LOF.\n",
    "    Returns boolean mask.\n",
    "    \"\"\"\n",
    "    top_knn = df.nsmallest(c, knn_rank_col).index\n",
    "    top_lof = df.nsmallest(c, lof_rank_col).index\n",
    "    candidates = df.index.isin(top_knn) | df.index.isin(top_lof)\n",
    "    \n",
    "    n_candidates = candidates.sum()\n",
    "    print(f\"Selected {n_candidates} candidates (union of top-{c} from kNN and LOF)\")\n",
    "    print(f\"  - Top-{c} kNN: {len(top_knn)}\")\n",
    "    print(f\"  - Top-{c} LOF: {len(top_lof)}\")\n",
    "    print(f\"  - Overlap: {len(set(top_knn) & set(top_lof))}\")\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "# ==========================================\n",
    "# FORMULA IMPLEMENTATIONS\n",
    "# ==========================================\n",
    "\n",
    "def compute_formulas(df, candidate_mask, knn_rank_col='knn_rank', lof_rank_col='lof_rank',\n",
    "                     knn_score_col='knn_score', lof_score_col='lof_score'):\n",
    "    \"\"\"\n",
    "    Compute rank-based AND score-based globality formulas for candidates only.\n",
    "    All formulas output values where:\n",
    "      - Positive → Global outlier (kNN ranks/scores it worse)\n",
    "      - Negative → Local outlier (LOF ranks/scores it worse)\n",
    "      - Near 0 → Ambiguous\n",
    "    \"\"\"\n",
    "    # Extract candidate data\n",
    "    knn_ranks = df.loc[candidate_mask, knn_rank_col].values\n",
    "    lof_ranks = df.loc[candidate_mask, lof_rank_col].values\n",
    "    knn_scores = df.loc[candidate_mask, knn_score_col].values\n",
    "    lof_scores = df.loc[candidate_mask, lof_score_col].values\n",
    "    n = len(df)\n",
    "    \n",
    "    # Initialize all formula columns with NaN\n",
    "    formula_cols = ['f0_simple', 'f1_grounded', 'f2_normalized', 'f3_percentile', \n",
    "                    'f4_avg_grounded', 'f5_score_ratio', 'f6_score_diff', \n",
    "                    'f7_log_ratio', 'f8_hybrid', 'f9_knn_direct', 'f10_lof_inverse', \n",
    "                    'f11_contrast']\n",
    "    \n",
    "    for col in formula_cols:\n",
    "        df[col] = np.nan\n",
    "    \n",
    "    # ==========================================\n",
    "    # RANK-BASED FORMULAS\n",
    "    # ==========================================\n",
    "    \n",
    "    # F0: Simple Rank Difference (BASELINE)\n",
    "    df.loc[candidate_mask, 'f0_simple'] = lof_ranks - knn_ranks\n",
    "    \n",
    "    # F1: Grounded Rank Difference (PRIMARY TARGET)\n",
    "    df.loc[candidate_mask, 'f1_grounded'] = (lof_ranks - knn_ranks) / (lof_ranks + knn_ranks + 1)\n",
    "    \n",
    "    # F2: Normalized Difference\n",
    "    df.loc[candidate_mask, 'f2_normalized'] = (lof_ranks - knn_ranks) / np.maximum(lof_ranks, knn_ranks)\n",
    "    \n",
    "    # F3: Percentile-Based Difference\n",
    "    lof_percentile = lof_ranks / n\n",
    "    knn_percentile = knn_ranks / n\n",
    "    df.loc[candidate_mask, 'f3_percentile'] = lof_percentile - knn_percentile\n",
    "    \n",
    "    # F4: Average-Grounded Difference\n",
    "    avg_rank = (lof_ranks + knn_ranks) / 2\n",
    "    df.loc[candidate_mask, 'f4_avg_grounded'] = (lof_ranks - knn_ranks) / (avg_rank + 1)\n",
    "    \n",
    "    # ==========================================\n",
    "    # SCORE-BASED FORMULAS\n",
    "    # ==========================================\n",
    "    \n",
    "    # F5: Score Ratio (inverted so positive = global)\n",
    "    # High LOF/kNN ratio means LOF thinks it's more anomalous = local\n",
    "    # We invert: high kNN/LOF = global\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = knn_scores / lof_scores\n",
    "        # Normalize to [-1, 1] range using log\n",
    "        log_ratio = np.log(ratio)\n",
    "        # Clip extreme values\n",
    "        log_ratio = np.clip(log_ratio, -5, 5)\n",
    "        # Normalize to [-1, 1]\n",
    "        df.loc[candidate_mask, 'f5_score_ratio'] = log_ratio / 5\n",
    "    \n",
    "    # F6: Normalized Score Difference\n",
    "    df.loc[candidate_mask, 'f6_score_diff'] = (lof_scores - knn_scores) / (lof_scores + knn_scores + 1e-10)\n",
    "    \n",
    "    # F7: Log-Ratio (LOF/kNN)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        log_ratio = np.log(lof_scores / knn_scores)\n",
    "        log_ratio = np.clip(log_ratio, -5, 5)\n",
    "        df.loc[candidate_mask, 'f7_log_ratio'] = log_ratio / 5\n",
    "    \n",
    "    # F8: Hybrid - Rank difference weighted by score magnitude\n",
    "    score_magnitude = np.sqrt(lof_scores * knn_scores)\n",
    "    # Normalize score magnitude to [0, 1]\n",
    "    score_magnitude = (score_magnitude - score_magnitude.min()) / (score_magnitude.max() - score_magnitude.min() + 1e-10)\n",
    "    rank_diff = (lof_ranks - knn_ranks) / (lof_ranks + knn_ranks + 1)\n",
    "    df.loc[candidate_mask, 'f8_hybrid'] = rank_diff * (0.5 + score_magnitude)\n",
    "    \n",
    "    # ==========================================\n",
    "    # DIRECT SCORE INDICATORS (NEW - SIMPLE!)\n",
    "    # ==========================================\n",
    "    \n",
    "    # F9: kNN Score as Globality (YOUR IDEA!)\n",
    "    # High kNN score = far from neighbors = GLOBAL\n",
    "    # Normalize to [-1, 1] for consistency\n",
    "    knn_normalized = (knn_scores - knn_scores.min()) / (knn_scores.max() - knn_scores.min() + 1e-10)\n",
    "    df.loc[candidate_mask, 'f9_knn_direct'] = 2 * knn_normalized - 1  # Scale to [-1, 1]\n",
    "    \n",
    "    # F10: Inverse LOF Score as Locality\n",
    "    # High LOF = local anomaly, so inverse for comparison\n",
    "    lof_normalized = (lof_scores - lof_scores.min()) / (lof_scores.max() - lof_scores.min() + 1e-10)\n",
    "    df.loc[candidate_mask, 'f10_lof_inverse'] = -(2 * lof_normalized - 1)  # Inverted\n",
    "    \n",
    "    # F11: Simple Score Contrast (kNN strong, LOF weak = global)\n",
    "    # Normalize both, then subtract\n",
    "    df.loc[candidate_mask, 'f11_contrast'] = knn_normalized - lof_normalized\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 1. MAIN COMPARISON GRID (2×4)\n",
    "# ==========================================\n",
    "\n",
    "def plot_main_comparison_grid(df, candidate_mask):\n",
    "    \"\"\"\n",
    "    Main hero visualization: Compare ground truth, majority voting, and top formulas.\n",
    "    Only candidates are colored, all others are gray background.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Color schemes\n",
    "    discrete_colors = {\n",
    "        'normal': 'lightgray',\n",
    "        'global': 'red',\n",
    "        'local': 'blue',\n",
    "        'tie': 'purple'\n",
    "    }\n",
    "    \n",
    "    # Plot configurations - select best formulas to show\n",
    "    plots = [\n",
    "        ('ground_truth', 'Ground Truth (Binary Labels)'),\n",
    "        ('majority_voting', 'Majority Voting (Discrete)'),\n",
    "        ('f9_knn_direct', 'F9: kNN_score (normalized) ⭐'),\n",
    "        ('f11_contrast', 'F11: kNN_norm - LOF_norm ⭐'),\n",
    "        ('f1_grounded', 'F1: (LOF_rank - kNN_rank) / (LOF_rank + kNN_rank + 1)'),\n",
    "        ('f6_score_diff', 'F6: (LOF_score - kNN_score) / (LOF_score + kNN_score)'),\n",
    "        ('f8_hybrid', 'F8: [(LOF_rank - kNN_rank) / Σranks] × √(LOF·kNN)'),\n",
    "        ('f0_simple', 'F0: LOF_rank - kNN_rank')\n",
    "    ]\n",
    "    \n",
    "    for idx, (plot_type, title) in enumerate(plots):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Plot background (all normal points)\n",
    "        ax.scatter(df.loc[~candidate_mask, 'attribute_1'], \n",
    "                  df.loc[~candidate_mask, 'attribute_2'],\n",
    "                  c='lightgray', s=15, alpha=0.2, label='_nolegend_')\n",
    "        \n",
    "        # --- GROUND TRUTH ---\n",
    "        if plot_type == 'ground_truth':\n",
    "            # Candidates only\n",
    "            cand_df = df[candidate_mask]\n",
    "            normal_mask = cand_df['is_outlier'] == 0\n",
    "            outlier_mask = cand_df['is_outlier'] == 1\n",
    "            \n",
    "            ax.scatter(cand_df.loc[normal_mask, 'attribute_1'], \n",
    "                      cand_df.loc[normal_mask, 'attribute_2'],\n",
    "                      c='gray', s=80, alpha=0.6, edgecolors='black', \n",
    "                      linewidth=0.5, label=f'Normal candidates ({normal_mask.sum()})')\n",
    "            ax.scatter(cand_df.loc[outlier_mask, 'attribute_1'], \n",
    "                      cand_df.loc[outlier_mask, 'attribute_2'],\n",
    "                      c='red', s=120, alpha=0.9, edgecolors='black', \n",
    "                      linewidth=0.8, label=f'True outliers ({outlier_mask.sum()})')\n",
    "            ax.legend(loc='best', fontsize=9)\n",
    "        \n",
    "        # --- MAJORITY VOTING ---\n",
    "        elif plot_type == 'majority_voting' and 'classification' in df.columns:\n",
    "            cand_df = df[candidate_mask]\n",
    "            for cls in ['normal', 'global', 'local', 'tie']:\n",
    "                mask = cand_df['classification'] == cls\n",
    "                if mask.any():\n",
    "                    ax.scatter(cand_df.loc[mask, 'attribute_1'], \n",
    "                              cand_df.loc[mask, 'attribute_2'],\n",
    "                              c=discrete_colors[cls],\n",
    "                              s=120 if cls in ['global', 'local'] else 80,\n",
    "                              alpha=0.85 if cls in ['global', 'local'] else 0.6,\n",
    "                              edgecolors='black',\n",
    "                              linewidth=0.7,\n",
    "                              label=f\"{cls.capitalize()} ({mask.sum()})\")\n",
    "            ax.legend(loc='best', fontsize=9)\n",
    "        \n",
    "        # --- FORMULAS (CONTINUOUS GRADIENT) ---\n",
    "        else:\n",
    "            if plot_type in df.columns:\n",
    "                cand_df = df[candidate_mask]\n",
    "                scores = cand_df[plot_type].values\n",
    "                \n",
    "                # Remove NaN values\n",
    "                valid_mask = ~np.isnan(scores)\n",
    "                if valid_mask.sum() == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Determine vmin/vmax based on formula type\n",
    "                if plot_type == 'f0_simple':\n",
    "                    vmin, vmax = np.percentile(scores[valid_mask], [5, 95])\n",
    "                    vmax = max(abs(vmin), abs(vmax))\n",
    "                    vmin = -vmax\n",
    "                else:\n",
    "                    vmin, vmax = -1, 1\n",
    "                \n",
    "                scatter = ax.scatter(cand_df.loc[valid_mask, 'attribute_1'], \n",
    "                                    cand_df.loc[valid_mask, 'attribute_2'],\n",
    "                                    c=scores[valid_mask], cmap='RdBu_r', \n",
    "                                    s=120, alpha=0.85, \n",
    "                                    edgecolors='black', linewidth=0.7,\n",
    "                                    vmin=vmin, vmax=vmax)\n",
    "                \n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label('Global ← → Local', fontsize=9)\n",
    "                cbar.ax.tick_params(labelsize=8)\n",
    "        \n",
    "        ax.set_title(title, fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Attribute 1', fontsize=9)\n",
    "        ax.set_ylabel('Attribute 2', fontsize=9)\n",
    "        ax.grid(alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Comparison: Candidates Only (n={candidate_mask.sum()})', \n",
    "                 fontsize=15, fontweight='bold', y=0.995)\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 2. FORMULA SHOWCASE (All Formulas)\n",
    "# ==========================================\n",
    "\n",
    "def plot_all_formulas_showcase(df, candidate_mask):\n",
    "    \"\"\"\n",
    "    Show all 12 formulas in a comprehensive grid.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(28, 18))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    formulas = [\n",
    "        ('f9_knn_direct', 'F9: kNN_score (normalized) ⭐'),\n",
    "        ('f11_contrast', 'F11: kNN_norm - LOF_norm ⭐'),\n",
    "        ('f10_lof_inverse', 'F10: -LOF_score (normalized)'),\n",
    "        ('f1_grounded', 'F1: (LOF_rank - kNN_rank) / (Σranks + 1)'),\n",
    "        ('f6_score_diff', 'F6: (LOF_score - kNN_score) / (Σscores)'),\n",
    "        ('f8_hybrid', 'F8: rank_diff × √(LOF·kNN)'),\n",
    "        ('f0_simple', 'F0: LOF_rank - kNN_rank'),\n",
    "        ('f2_normalized', 'F2: (LOF_rank - kNN_rank) / max(ranks)'),\n",
    "        ('f3_percentile', 'F3: (LOF_rank/N) - (kNN_rank/N)'),\n",
    "        ('f4_avg_grounded', 'F4: (LOF_rank - kNN_rank) / (avg_rank + 1)'),\n",
    "        ('f5_score_ratio', 'F5: log(kNN_score / LOF_score) / 5'),\n",
    "        ('f7_log_ratio', 'F7: log(LOF_score / kNN_score) / 5')\n",
    "    ]\n",
    "    \n",
    "    for idx, (col, title) in enumerate(formulas):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Background\n",
    "        ax.scatter(df.loc[~candidate_mask, 'attribute_1'], \n",
    "                  df.loc[~candidate_mask, 'attribute_2'],\n",
    "                  c='lightgray', s=15, alpha=0.2)\n",
    "        \n",
    "        # Candidates\n",
    "        cand_df = df[candidate_mask]\n",
    "        scores = cand_df[col].values\n",
    "        valid_mask = ~np.isnan(scores)\n",
    "        \n",
    "        if valid_mask.sum() > 0:\n",
    "            if col == 'f0_simple':\n",
    "                vmin, vmax = np.percentile(scores[valid_mask], [5, 95])\n",
    "                vmax = max(abs(vmin), abs(vmax))\n",
    "                vmin = -vmax\n",
    "            else:\n",
    "                vmin, vmax = -1, 1\n",
    "            \n",
    "            scatter = ax.scatter(cand_df.loc[valid_mask, 'attribute_1'], \n",
    "                                cand_df.loc[valid_mask, 'attribute_2'],\n",
    "                                c=scores[valid_mask], cmap='RdBu_r',\n",
    "                                s=100, alpha=0.85,\n",
    "                                edgecolors='black', linewidth=0.6,\n",
    "                                vmin=vmin, vmax=vmax)\n",
    "            \n",
    "            cbar = plt.colorbar(scatter, ax=ax)\n",
    "            cbar.set_label('Score', fontsize=8)\n",
    "            cbar.ax.tick_params(labelsize=7)\n",
    "        \n",
    "        ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Attribute 1', fontsize=8)\n",
    "        ax.set_ylabel('Attribute 2', fontsize=8)\n",
    "        ax.grid(alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('All Formula Results (Candidates Only)', fontsize=15, fontweight='bold', y=0.995)\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 3. TOP-K TABLES\n",
    "# ==========================================\n",
    "\n",
    "def print_top_k_table(df, candidate_mask, formula_col, formula_name, k=10):\n",
    "    \"\"\"\n",
    "    Print top K most global and most local candidates for a formula.\n",
    "    \"\"\"\n",
    "    cand_df = df[candidate_mask].copy()\n",
    "    cand_df = cand_df.dropna(subset=[formula_col])\n",
    "    \n",
    "    if len(cand_df) == 0:\n",
    "        print(f\"\\n⚠️  No valid data for {formula_name}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*110)\n",
    "    print(f\"{formula_name.upper()} - TOP {k} CANDIDATES ANALYSIS\")\n",
    "    print(\"=\"*110)\n",
    "    \n",
    "    # Top K Most Global\n",
    "    print(f\"\\n🔴 TOP {k} MOST GLOBAL (Highest Scores - Isolated from Everything):\")\n",
    "    print(\"-\"*110)\n",
    "    top_global = cand_df.nlargest(min(k, len(cand_df)), formula_col)\n",
    "    print(f\"{'Index':<8} {'Attr1':<10} {'Attr2':<10} {'Score':<12} {'kNN_rank':<12} {'LOF_rank':<12} {'True_Label':<12}\")\n",
    "    print(\"-\"*110)\n",
    "    for idx, row in top_global.iterrows():\n",
    "        label = 'OUTLIER' if row['is_outlier'] == 1 else 'normal'\n",
    "        print(f\"{idx:<8} {row['attribute_1']:<10.3f} {row['attribute_2']:<10.3f} \"\n",
    "              f\"{row[formula_col]:<12.4f} {row['knn_rank']:<12} {row['lof_rank']:<12} {label:<12}\")\n",
    "    \n",
    "    # Top K Most Local\n",
    "    print(f\"\\n🔵 TOP {k} MOST LOCAL (Lowest Scores - Locally Anomalous Only):\")\n",
    "    print(\"-\"*110)\n",
    "    top_local = cand_df.nsmallest(min(k, len(cand_df)), formula_col)\n",
    "    print(f\"{'Index':<8} {'Attr1':<10} {'Attr2':<10} {'Score':<12} {'kNN_rank':<12} {'LOF_rank':<12} {'True_Label':<12}\")\n",
    "    print(\"-\"*110)\n",
    "    for idx, row in top_local.iterrows():\n",
    "        label = 'OUTLIER' if row['is_outlier'] == 1 else 'normal'\n",
    "        print(f\"{idx:<8} {row['attribute_1']:<10.3f} {row['attribute_2']:<10.3f} \"\n",
    "              f\"{row[formula_col]:<12.4f} {row['knn_rank']:<12} {row['lof_rank']:<12} {label:<12}\")\n",
    "    print(\"=\"*110)\n",
    "\n",
    "# ==========================================\n",
    "# 4. DISTRIBUTION HISTOGRAMS (Candidates Only)\n",
    "# ==========================================\n",
    "\n",
    "def plot_candidate_distributions(df, candidate_mask):\n",
    "    \"\"\"\n",
    "    Show distribution of scores for all formulas (candidates only).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(26, 16))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    formulas = [\n",
    "        ('f9_knn_direct', 'F9: kNN_score (norm) ⭐'),\n",
    "        ('f11_contrast', 'F11: kNN_norm - LOF_norm ⭐'),\n",
    "        ('f10_lof_inverse', 'F10: -LOF_score (norm)'),\n",
    "        ('f1_grounded', 'F1: (LOF_r - kNN_r) / (Σr+1)'),\n",
    "        ('f6_score_diff', 'F6: (LOF_s - kNN_s) / Σs'),\n",
    "        ('f8_hybrid', 'F8: r_diff × √(LOF·kNN)'),\n",
    "        ('f0_simple', 'F0: LOF_rank - kNN_rank'),\n",
    "        ('f2_normalized', 'F2: (LOF_r - kNN_r) / max(r)'),\n",
    "        ('f3_percentile', 'F3: (LOF_r/N) - (kNN_r/N)'),\n",
    "        ('f4_avg_grounded', 'F4: (LOF_r - kNN_r) / (avg+1)'),\n",
    "        ('f5_score_ratio', 'F5: log(kNN_s / LOF_s) / 5'),\n",
    "        ('f7_log_ratio', 'F7: log(LOF_s / kNN_s) / 5')\n",
    "    ]\n",
    "    \n",
    "    for idx, (col, title) in enumerate(formulas):\n",
    "        ax = axes[idx]\n",
    "        cand_df = df[candidate_mask]\n",
    "        scores = cand_df[col].dropna().values\n",
    "        \n",
    "        if len(scores) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Plot histogram\n",
    "        ax.hist(scores, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "        \n",
    "        # Add vertical line at 0\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Neutral (0)')\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_val = scores.mean()\n",
    "        ax.axvline(mean_val, color='green', linestyle='--', linewidth=2, \n",
    "                  label=f'Mean: {mean_val:.3f}')\n",
    "        \n",
    "        ax.set_title(title, fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Score', fontsize=9)\n",
    "        ax.set_ylabel('Frequency', fontsize=9)\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "        ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Distribution of Formula Scores (Candidates Only, n={candidate_mask.sum()})', \n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 5. SUMMARY STATISTICS TABLE\n",
    "# ==========================================\n",
    "\n",
    "def print_formula_statistics(df, candidate_mask):\n",
    "    \"\"\"\n",
    "    Print summary statistics for all formulas (candidates only).\n",
    "    \"\"\"\n",
    "    cand_df = df[candidate_mask]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*110)\n",
    "    print(\"FORMULA STATISTICS SUMMARY (CANDIDATES ONLY)\")\n",
    "    print(\"=\"*110)\n",
    "    \n",
    "    formulas = {\n",
    "        'f9_knn_direct': 'F9: kNN_score (normalized) ⭐',\n",
    "        'f11_contrast': 'F11: kNN_norm - LOF_norm ⭐',\n",
    "        'f10_lof_inverse': 'F10: -LOF_score (normalized)',\n",
    "        'f0_simple': 'F0: LOF_rank - kNN_rank',\n",
    "        'f1_grounded': 'F1: (LOF_rank - kNN_rank) / (Σranks + 1)',\n",
    "        'f2_normalized': 'F2: (LOF_rank - kNN_rank) / max(ranks)',\n",
    "        'f3_percentile': 'F3: (LOF_rank/N) - (kNN_rank/N)',\n",
    "        'f4_avg_grounded': 'F4: (LOF_rank - kNN_rank) / (avg_rank + 1)',\n",
    "        'f5_score_ratio': 'F5: log(kNN_score / LOF_score) / 5',\n",
    "        'f6_score_diff': 'F6: (LOF_score - kNN_score) / (Σscores)',\n",
    "        'f7_log_ratio': 'F7: log(LOF_score / kNN_score) / 5',\n",
    "        'f8_hybrid': 'F8: rank_diff × √(LOF·kNN)'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'Formula':<35} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10} {'Range':<10}\")\n",
    "    print(\"-\"*110)\n",
    "    \n",
    "    for col, name in formulas.items():\n",
    "        scores = cand_df[col].dropna().values\n",
    "        if len(scores) > 0:\n",
    "            print(f\"{name:<35} {scores.mean():<10.4f} {scores.std():<10.4f} \"\n",
    "                  f\"{scores.min():<10.4f} {scores.max():<10.4f} {scores.max()-scores.min():<10.4f}\")\n",
    "    \n",
    "    # Breakdown by true labels (for candidates only)\n",
    "    print(f\"\\n{'Formula':<35} {'Mean (Normal)':<15} {'Mean (Outliers)':<15} {'Difference':<15}\")\n",
    "    print(\"-\"*110)\n",
    "    \n",
    "    for col, name in formulas.items():\n",
    "        normal_scores = cand_df[cand_df['is_outlier'] == 0][col].dropna()\n",
    "        outlier_scores = cand_df[cand_df['is_outlier'] == 1][col].dropna()\n",
    "        \n",
    "        if len(normal_scores) > 0 and len(outlier_scores) > 0:\n",
    "            mean_normal = normal_scores.mean()\n",
    "            mean_outlier = outlier_scores.mean()\n",
    "            diff = mean_outlier - mean_normal\n",
    "            print(f\"{name:<35} {mean_normal:<15.4f} {mean_outlier:<15.4f} {diff:<15.4f}\")\n",
    "    \n",
    "    print(\"=\"*110)\n",
    "\n",
    "# ==========================================\n",
    "# MASTER FUNCTION: RUN ALL ANALYSES\n",
    "# ==========================================\n",
    "\n",
    "def run_complete_analysis(df, c=50, show_all_formulas=True, show_top_k=True, k=10):\n",
    "    \"\"\"\n",
    "    Run the complete analysis suite:\n",
    "    1. Filter to top-c candidates\n",
    "    2. Compute all formulas for candidates only\n",
    "    3. Show main comparison grid\n",
    "    4. Show all formulas showcase\n",
    "    5. Print top-K tables\n",
    "    6. Show distributions\n",
    "    7. Print statistics\n",
    "    \"\"\"\n",
    "    print(\"=\"*110)\n",
    "    print(\"STARTING COMPREHENSIVE FORMULA ANALYSIS (CANDIDATES ONLY)\")\n",
    "    print(\"=\"*110)\n",
    "    \n",
    "    # 1. Get candidates\n",
    "    candidate_mask = get_candidate_mask(df, c=c)\n",
    "    \n",
    "    # 2. Compute all formulas\n",
    "    df = compute_formulas(df, candidate_mask)\n",
    "    print(f\"✓ Computed 12 formulas (5 rank-based + 4 score-based + 3 direct indicators)\")\n",
    "    print(f\"  ⭐ NEW: F9 (kNN Direct), F10 (LOF Inverse), F11 (Contrast) - Simple score-based!\")\n",
    "    \n",
    "    # 3. Main comparison grid\n",
    "    print(\"\\n📊 Generating main comparison grid...\")\n",
    "    plot_main_comparison_grid(df, candidate_mask)\n",
    "    \n",
    "    # 4. All formulas showcase\n",
    "    if show_all_formulas:\n",
    "        print(\"\\n📊 Generating complete formula showcase...\")\n",
    "        plot_all_formulas_showcase(df, candidate_mask)\n",
    "    \n",
    "    # 5. Top-K tables\n",
    "    if show_top_k:\n",
    "        print(\"\\n📋 Generating top-K tables...\")\n",
    "        formulas = [\n",
    "            ('f9_knn_direct', 'F9: kNN_score (normalized)'),\n",
    "            ('f11_contrast', 'F11: kNN_norm - LOF_norm'),\n",
    "            ('f1_grounded', 'F1: (LOF_rank - kNN_rank) / (Σranks+1)'),\n",
    "            ('f6_score_diff', 'F6: (LOF_score - kNN_score) / Σscores'),\n",
    "            ('f0_simple', 'F0: LOF_rank - kNN_rank'),\n",
    "            ('f8_hybrid', 'F8: rank_diff × √(LOF·kNN)')\n",
    "        ]\n",
    "        \n",
    "        for col, name in formulas:\n",
    "            print_top_k_table(df, candidate_mask, col, name, k)\n",
    "    \n",
    "    # 6. Distributions\n",
    "    print(\"\\n📊 Generating distribution histograms...\")\n",
    "    plot_candidate_distributions(df, candidate_mask)\n",
    "    \n",
    "    # 7. Statistics\n",
    "    print_formula_statistics(df, candidate_mask)\n",
    "    \n",
    "    print(\"\\n✓ Complete analysis finished!\")\n",
    "    print(f\"✓ Analyzed {candidate_mask.sum()} candidates from {len(df)} total points\")\n",
    "    return df, candidate_mask\n",
    "\n",
    "# ==========================================\n",
    "# HOW TO USE THIS CODE\n",
    "# ==========================================\n",
    "\"\"\"\n",
    "# USAGE EXAMPLE:\n",
    "\n",
    "# Assuming you have df with these columns:\n",
    "# - 'attribute_1', 'attribute_2' (features)\n",
    "# - 'is_outlier' (binary ground truth: 37 outliers)\n",
    "# - 'knn_rank', 'lof_rank' (from k-NN and LOF detectors)\n",
    "# - 'knn_score', 'lof_score' (anomaly scores)\n",
    "# - 'classification' (from majority voting - optional)\n",
    "\n",
    "# Run the complete analysis (c=50 since we have 37 true outliers):\n",
    "df, candidate_mask = run_complete_analysis(df, c=50, show_all_formulas=True, show_top_k=True, k=10)\n",
    "\n",
    "# NOTATION USED IN PLOTS:\n",
    "# - kNN_score, LOF_score: Raw anomaly scores from detectors\n",
    "# - kNN_rank, LOF_rank: Ranks (1 = most anomalous)\n",
    "# - kNN_norm, LOF_norm: Normalized scores to [0, 1]\n",
    "# - Σranks = LOF_rank + kNN_rank\n",
    "# - Σscores = LOF_score + kNN_score\n",
    "# - r = rank (shortened for space)\n",
    "# - s = score (shortened for space)\n",
    "\n",
    "# NEW SIMPLE FORMULAS TO CHECK FIRST:\n",
    "# - F9: kNN_score (normalized) - High kNN = far from neighbors = GLOBAL ⭐\n",
    "# - F11: kNN_norm - LOF_norm - Contrast shows which detector is stronger\n",
    "# - F10: -LOF_score (normalized) - Inverted LOF for comparison\n",
    "\n",
    "# The results will show:\n",
    "# - Only the top-50 candidates (union of kNN and LOF top-50)\n",
    "# - All background points in light gray\n",
    "# - Clear gradient coloring for candidates only\n",
    "# - F9 should show clear global vs local separation!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, candidate_mask = run_complete_analysis(df, c=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Extra Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Distribution of Votes (Hist + KDE)\n",
    "# ======================================\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.histplot(df['votes_global'], kde=True, bins=20, color='red', alpha=0.5, label='Global votes')\n",
    "sns.histplot(df['votes_local'], kde=True, bins=20, color='blue', alpha=0.5, label='Local votes')\n",
    "\n",
    "plt.title(\"Distribution of Global vs Local Votes\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Votes\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_classifier(df, c_values, knn_rank_col='knn_rank', lof_rank_col='lof_rank'):\n",
    "    \"\"\"\n",
    "    Classify anomalies as local or global using majority voting across multiple thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame containing k-NN and LOF ranks\n",
    "    c_values : list or array\n",
    "        List of top-c thresholds to test (e.g., [10, 20, 30, 40, 50, 100])\n",
    "    knn_rank_col : str\n",
    "        Column name for k-NN ranks\n",
    "    lof_rank_col : str\n",
    "        Column name for LOF ranks\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added columns:\n",
    "        - 'votes_global': number of global votes\n",
    "        - 'votes_local': number of local votes\n",
    "        - 'classification': 'global', 'local', or 'normal' (no votes)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize vote counters for each point\n",
    "    votes_global = np.zeros(len(df), dtype=int)\n",
    "    votes_local = np.zeros(len(df), dtype=int)\n",
    "    \n",
    "    # For each threshold c\n",
    "    for c in c_values:\n",
    "        # Get top c points by k-NN rank (highest rank = most anomalous)\n",
    "        top_knn = set(df.nsmallest(c, knn_rank_col).index)\n",
    "        \n",
    "        # Get top c points by LOF rank (highest rank = most anomalous)\n",
    "        top_lof = set(df.nsmallest(c, lof_rank_col).index)\n",
    "        \n",
    "        # Get all points that are in top-c of at least one method\n",
    "        all_top = top_knn.union(top_lof)\n",
    "        \n",
    "        for idx in all_top:\n",
    "            in_knn = idx in top_knn\n",
    "            in_lof = idx in top_lof\n",
    "            \n",
    "            if in_knn and in_lof:\n",
    "                # Point is in both → Global outlier\n",
    "                votes_global[idx] += 1\n",
    "            elif in_lof and not in_knn:\n",
    "                # Point is only in LOF → Local outlier\n",
    "                votes_local[idx] += 1\n",
    "            # If only in k-NN, we don't vote (ambiguous case)\n",
    "    \n",
    "    # Add votes to dataframe\n",
    "    df['votes_global'] = votes_global\n",
    "    df['votes_local'] = votes_local\n",
    "    df['total_votes'] = votes_global + votes_local\n",
    "    \n",
    "    # Classify based on majority voting\n",
    "    classifications = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if votes_global[i] > votes_local[i]:\n",
    "            classifications.append('global')\n",
    "        elif votes_local[i] > votes_global[i]:\n",
    "            classifications.append('local')\n",
    "        elif votes_global[i] == votes_local[i] and votes_global[i] > 0:\n",
    "            classifications.append('tie')\n",
    "        else:\n",
    "            classifications.append('normal')\n",
    "    \n",
    "    df['classification'] = classifications\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define range of thresholds to test\n",
    "c_values = [5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "# Apply majority voting\n",
    "df = majority_voting_classifier(df, c_values)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"MAJORITY VOTING CLASSIFICATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTested thresholds: {c_values}\")\n",
    "print(f\"Number of threshold values: {len(c_values)}\")\n",
    "print(\"\\nClassification counts:\")\n",
    "print(df['classification'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Vote statistics by classification:\")\n",
    "print(\"-\" * 80)\n",
    "for cls in ['global', 'local', 'tie', 'normal']:\n",
    "    subset = df[df['classification'] == cls]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()}:\")\n",
    "        print(f\"  Count: {len(subset)}\")\n",
    "        print(f\"  Avg global votes: {subset['votes_global'].mean():.2f}\")\n",
    "        print(f\"  Avg local votes: {subset['votes_local'].mean():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classification results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Define colors for each classification\n",
    "color_map = {\n",
    "    'normal': 'lightgray',\n",
    "    'global': 'red',\n",
    "    'local': 'blue',\n",
    "    'tie': 'purple'\n",
    "}\n",
    "\n",
    "# Plot 1: Classification (categorical colors)\n",
    "ax1 = axes[0]\n",
    "for cls in ['normal', 'global', 'local', 'tie']:\n",
    "    mask = df['classification'] == cls\n",
    "    if mask.sum() > 0:\n",
    "        ax1.scatter(\n",
    "            df.loc[mask, 'attribute_1'],\n",
    "            df.loc[mask, 'attribute_2'],\n",
    "            c=color_map[cls],\n",
    "            s=50 if cls in ['global', 'local'] else 20,\n",
    "            alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "            label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "            edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax1.set_title('Local vs Global Outlier Classification\\n(Majority Voting)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Total votes (only for classified anomalies)\n",
    "ax2 = axes[1]\n",
    "anomaly_mask = df['classification'].isin(['global', 'local'])\n",
    "normal_mask = ~anomaly_mask\n",
    "\n",
    "# Plot normal points in background\n",
    "ax2.scatter(\n",
    "    df.loc[normal_mask, 'attribute_1'],\n",
    "    df.loc[normal_mask, 'attribute_2'],\n",
    "    c='lightgray',\n",
    "    s=20,\n",
    "    alpha=0.3,\n",
    "    label='Normal/Tie'\n",
    ")\n",
    "\n",
    "# Plot anomalies colored by total votes\n",
    "scatter = ax2.scatter(\n",
    "    df.loc[anomaly_mask, 'attribute_1'],\n",
    "    df.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df.loc[anomaly_mask, 'total_votes'],\n",
    "    cmap='viridis',\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "ax2.set_title('Total Votes Received\\n(across all thresholds)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter, ax=ax2)\n",
    "cbar.set_label('Total votes', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed comparison with ground truth labels\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Plot 1: Ground Truth Labels\n",
    "ax1 = axes[0, 0]\n",
    "for is_out, color, label in [(0, 'blue', 'Normal'), (1, 'red', 'Outlier')]:\n",
    "    mask = df['is_outlier'] == is_out\n",
    "    ax1.scatter(\n",
    "        df.loc[mask, 'attribute_1'],\n",
    "        df.loc[mask, 'attribute_2'],\n",
    "        c=color,\n",
    "        s=40 if is_out else 20,\n",
    "        alpha=0.6,\n",
    "        label=f'{label} ({mask.sum()})',\n",
    "        marker='x' if is_out else 'o',\n",
    "        edgecolors='black' if is_out else 'none',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "ax1.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax1.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax1.set_title('Ground Truth Labels', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Our Classification\n",
    "ax2 = axes[0, 1]\n",
    "for cls, color in [('normal', 'lightgray'), ('global', 'red'), ('local', 'blue'), ('tie', 'purple')]:\n",
    "    mask = df['classification'] == cls\n",
    "    if mask.sum() > 0:\n",
    "        ax2.scatter(\n",
    "            df.loc[mask, 'attribute_1'],\n",
    "            df.loc[mask, 'attribute_2'],\n",
    "            c=color,\n",
    "            s=50 if cls in ['global', 'local'] else 20,\n",
    "            alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "            label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "            edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "ax2.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax2.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax2.set_title('Majority Vote Classification', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='best', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Voting details - Global votes\n",
    "ax3 = axes[1, 0]\n",
    "anomaly_mask = df['classification'].isin(['global', 'local'])\n",
    "normal_mask = ~anomaly_mask\n",
    "\n",
    "ax3.scatter(df.loc[normal_mask, 'attribute_1'], df.loc[normal_mask, 'attribute_2'],\n",
    "           c='lightgray', s=15, alpha=0.2)\n",
    "scatter3 = ax3.scatter(\n",
    "    df.loc[anomaly_mask, 'attribute_1'],\n",
    "    df.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df.loc[anomaly_mask, 'votes_global'],\n",
    "    cmap='Reds',\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax3.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax3.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax3.set_title('Global Votes (higher = more global)', fontsize=13, fontweight='bold')\n",
    "cbar3 = plt.colorbar(scatter3, ax=ax3)\n",
    "cbar3.set_label('Global votes', fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Voting details - Local votes\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(df.loc[normal_mask, 'attribute_1'], df.loc[normal_mask, 'attribute_2'],\n",
    "           c='lightgray', s=15, alpha=0.2)\n",
    "scatter4 = ax4.scatter(\n",
    "    df.loc[anomaly_mask, 'attribute_1'],\n",
    "    df.loc[anomaly_mask, 'attribute_2'],\n",
    "    c=df.loc[anomaly_mask, 'votes_local'],\n",
    "    cmap='Blues',\n",
    "    s=50,\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax4.set_xlabel('Attribute 1', fontsize=11)\n",
    "ax4.set_ylabel('Attribute 2', fontsize=11)\n",
    "ax4.set_title('Local Votes (higher = more local)', fontsize=13, fontweight='bold')\n",
    "cbar4 = plt.colorbar(scatter4, ax=ax4)\n",
    "cbar4.set_label('Local votes', fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis: How do our classifications align with ground truth?\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASSIFICATION vs GROUND TRUTH ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cross-tabulation\n",
    "print(\"\\nCross-tabulation: Classification vs Ground Truth\")\n",
    "print(\"-\" * 80)\n",
    "crosstab = pd.crosstab(\n",
    "    df['classification'], \n",
    "    df['is_outlier'],\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "crosstab.columns = ['Normal (GT)', 'Outlier (GT)', 'Total']\n",
    "print(crosstab)\n",
    "\n",
    "# Among ground truth outliers, how are they classified?\n",
    "gt_outliers = df[df['is_outlier'] == 1]\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GROUND TRUTH OUTLIERS BREAKDOWN\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total ground truth outliers: {len(gt_outliers)}\")\n",
    "print(\"\\nHow are they classified?\")\n",
    "for cls in ['global', 'local', 'tie', 'normal']:\n",
    "    count = (gt_outliers['classification'] == cls).sum()\n",
    "    pct = count / len(gt_outliers) * 100 if len(gt_outliers) > 0 else 0\n",
    "    print(f\"  {cls.capitalize():10s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Show top examples of each type\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP EXAMPLES BY CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cls in ['global', 'local']:\n",
    "    subset = df[df['classification'] == cls].nlargest(5, 'total_votes')\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()} OUTLIERS (Top 5 by total votes):\")\n",
    "        print(\"-\" * 80)\n",
    "        cols_to_show = ['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                        'votes_global', 'votes_local', 'total_votes', 'is_outlier']\n",
    "        print(subset[cols_to_show].to_string(index=True))\n",
    "\n",
    "# Statistics on ranks\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RANK STATISTICS BY CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cls in ['global', 'local']:\n",
    "    subset = df[df['classification'] == cls]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{cls.upper()} outliers (n={len(subset)}):\")\n",
    "        print(f\"  k-NN rank - mean: {subset['knn_rank'].mean():.1f}, median: {subset['knn_rank'].median():.1f}, min: {subset['knn_rank'].min()}, max: {subset['knn_rank'].max()}\")\n",
    "        print(f\"  LOF rank  - mean: {subset['lof_rank'].mean():.1f}, median: {subset['lof_rank'].median():.1f}, min: {subset['lof_rank'].min()}, max: {subset['lof_rank'].max()}\")\n",
    "        print(f\"  Rank diff (LOF-kNN) - mean: {(subset['lof_rank'] - subset['knn_rank']).mean():.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Experiment with Different Threshold Ranges\n",
    "\n",
    "Let's see how the classification changes with different ranges of c values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different threshold strategies\n",
    "threshold_strategies = {\n",
    "    'Fine-grained (10-100)': list(range(10, 101, 10)),\n",
    "    'Coarse (10-200, step 20)': list(range(10, 201, 20)),\n",
    "    'Wide range (5-300)': [5, 10, 20, 30, 50, 75, 100, 150, 200, 250, 300],\n",
    "    'Small thresholds (5-50)': list(range(5, 51, 1)),\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (strategy_name, c_vals) in enumerate(threshold_strategies.items()):\n",
    "    # Create a copy of original dataframe\n",
    "    df_temp = df[['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', 'is_outlier']].copy()\n",
    "    \n",
    "    # Apply classification\n",
    "    df_temp = majority_voting_classifier(df_temp, c_vals)\n",
    "    \n",
    "    # Store summary\n",
    "    summary = {\n",
    "        'Strategy': strategy_name,\n",
    "        'Thresholds': c_vals,\n",
    "        'Global': (df_temp['classification'] == 'global').sum(),\n",
    "        'Local': (df_temp['classification'] == 'local').sum(),\n",
    "        'Tie': (df_temp['classification'] == 'tie').sum(),\n",
    "        'Normal': (df_temp['classification'] == 'normal').sum(),\n",
    "    }\n",
    "    results_summary.append(summary)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    for cls, color in [('normal', 'lightgray'), ('global', 'red'), ('local', 'blue'), ('tie', 'purple')]:\n",
    "        mask = df_temp['classification'] == cls\n",
    "        if mask.sum() > 0:\n",
    "            ax.scatter(\n",
    "                df_temp.loc[mask, 'attribute_1'],\n",
    "                df_temp.loc[mask, 'attribute_2'],\n",
    "                c=color,\n",
    "                s=50 if cls in ['global', 'local'] else 15,\n",
    "                alpha=0.7 if cls in ['global', 'local'] else 0.3,\n",
    "                label=f'{cls.capitalize()} ({mask.sum()})',\n",
    "                edgecolors='black' if cls in ['global', 'local'] else 'none',\n",
    "                linewidth=0.5\n",
    "            )\n",
    "    \n",
    "    ax.set_xlabel('Attribute 1', fontsize=10)\n",
    "    ax.set_ylabel('Attribute 2', fontsize=10)\n",
    "    ax.set_title(f'{strategy_name}\\n(c: {min(c_vals)}-{max(c_vals)}, n={len(c_vals)})', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARISON OF THRESHOLD STRATEGIES\")\n",
    "print(\"=\" * 80)\n",
    "comparison_df = pd.DataFrame(results_summary)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Export the classified data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classified data\n",
    "output_file = 'dfki_classified_local_global.csv'\n",
    "output_cols = [\n",
    "    'attribute_1', 'attribute_2', \n",
    "    'is_outlier',  # ground truth\n",
    "    'knn_score', 'knn_rank',\n",
    "    'lof_score', 'lof_rank',\n",
    "    'votes_global', 'votes_local', 'total_votes',\n",
    "    'classification'\n",
    "]\n",
    "\n",
    "df[output_cols].to_csv(output_file, index=False)\n",
    "print(f\"✓ Results saved to: {output_file}\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {len(output_cols)}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: DFKI Artificial (3000 samples)\")\n",
    "print(f\"Thresholds tested: {c_values}\")\n",
    "print(f\"\\nClassification results:\")\n",
    "print(df['classification'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n\\nKey insights:\")\n",
    "print(f\"  • Global outliers: Points consistently ranked high by BOTH k-NN and LOF\")\n",
    "print(f\"  • Local outliers: Points ranked high by LOF but NOT by k-NN\")\n",
    "print(f\"  • Majority voting: Classification based on votes across all thresholds\")\n",
    "\n",
    "# Show a few example points\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE CLASSIFICATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if (df['classification'] == 'global').any():\n",
    "    print(\"\\nTop GLOBAL outlier (by total votes):\")\n",
    "    global_example = df[df['classification'] == 'global'].nlargest(1, 'total_votes')\n",
    "    print(global_example[['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                           'votes_global', 'votes_local', 'total_votes']].to_string())\n",
    "\n",
    "if (df['classification'] == 'local').any():\n",
    "    print(\"\\nTop LOCAL outlier (by total votes):\")\n",
    "    local_example = df[df['classification'] == 'local'].nlargest(1, 'total_votes')\n",
    "    print(local_example[['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                          'votes_global', 'votes_local', 'total_votes']].to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Majority Voting Algorithm for Global vs Local Outlier Classification\n",
    "\n",
    "Key Idea:\n",
    "- For each threshold c (top c anomalies):\n",
    "  - If point is in top-c for BOTH kNN AND LOF → vote \"global\"\n",
    "  - If point is in top-c for LOF but NOT kNN → vote \"local\"\n",
    "- Aggregate votes across many c values\n",
    "- Classify by majority vote\n",
    "\"\"\"\n",
    "\n",
    "def majority_vote_classification(df, c_range, knn_rank_col='knn_rank', lof_rank_col='lof_rank'):\n",
    "    \"\"\"\n",
    "    Classify outliers as global or local using majority voting across multiple thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Must contain knn_rank and lof_rank columns\n",
    "    c_range : list or range\n",
    "        List of threshold values to test (e.g., [10, 20, 30, ..., 100])\n",
    "    knn_rank_col : str\n",
    "        Column name for k-NN ranks\n",
    "    lof_rank_col : str\n",
    "        Column name for LOF ranks\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added columns:\n",
    "        - 'global_votes': number of times classified as global\n",
    "        - 'local_votes': number of times classified as local\n",
    "        - 'total_votes': total votes received\n",
    "        - 'classification': 'global', 'local', or 'normal' (no votes)\n",
    "        - 'confidence': ratio of majority votes to total votes\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = len(df)\n",
    "    \n",
    "    # Initialize vote counters\n",
    "    global_votes = np.zeros(n_samples, dtype=int)\n",
    "    local_votes = np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    print(f\"Running majority voting across c = {list(c_range)}\")\n",
    "    print(f\"Total thresholds to test: {len(list(c_range))}\")\n",
    "    print()\n",
    "    \n",
    "    # Iterate through each threshold value\n",
    "    for c in c_range:\n",
    "        # Get top c indices for each algorithm\n",
    "        top_knn = set(df.nsmallest(c, knn_rank_col).index)\n",
    "        top_lof = set(df.nsmallest(c, lof_rank_col).index)\n",
    "        \n",
    "        # Points in both → global vote\n",
    "        global_outliers = top_knn & top_lof\n",
    "        \n",
    "        # Points in LOF but not kNN → local vote\n",
    "        local_outliers = top_lof - top_knn\n",
    "        \n",
    "        # Record votes\n",
    "        for idx in global_outliers:\n",
    "            global_votes[idx] += 1\n",
    "        \n",
    "        for idx in local_outliers:\n",
    "            local_votes[idx] += 1\n",
    "    \n",
    "    # Add results to dataframe\n",
    "    df_result = df.copy()\n",
    "    df_result['global_votes'] = global_votes\n",
    "    df_result['local_votes'] = local_votes\n",
    "    df_result['total_votes'] = global_votes + local_votes\n",
    "    \n",
    "    # Classify based on majority\n",
    "    classifications = []\n",
    "    confidences = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        g_votes = global_votes[i]\n",
    "        l_votes = local_votes[i]\n",
    "        total = g_votes + l_votes\n",
    "        \n",
    "        if total == 0:\n",
    "            classifications.append('normal')\n",
    "            confidences.append(0.0)\n",
    "        elif g_votes > l_votes:\n",
    "            classifications.append('global')\n",
    "            confidences.append(g_votes / total)\n",
    "        elif l_votes > g_votes:\n",
    "            classifications.append('local')\n",
    "            confidences.append(l_votes / total)\n",
    "        else:  # tie\n",
    "            classifications.append('tie')\n",
    "            confidences.append(0.5)\n",
    "    \n",
    "    df_result['classification'] = classifications\n",
    "    df_result['confidence'] = confidences\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLASSIFICATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Global outliers: {sum(np.array(classifications) == 'global')}\")\n",
    "    print(f\"Local outliers:  {sum(np.array(classifications) == 'local')}\")\n",
    "    print(f\"Ties:            {sum(np.array(classifications) == 'tie')}\")\n",
    "    print(f\"Normal points:   {sum(np.array(classifications) == 'normal')}\")\n",
    "    print()\n",
    "    \n",
    "    # Statistics on confidence\n",
    "    voted_mask = np.array(classifications) != 'normal'\n",
    "    if voted_mask.any():\n",
    "        voted_confidences = np.array(confidences)[voted_mask]\n",
    "        print(f\"Confidence statistics (for classified points):\")\n",
    "        print(f\"  Mean: {voted_confidences.mean():.3f}\")\n",
    "        print(f\"  Min:  {voted_confidences.min():.3f}\")\n",
    "        print(f\"  Max:  {voted_confidences.max():.3f}\")\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "\n",
    "def plot_classification_results(df, max_c, attr1='attribute_1', attr2='attribute_2'):\n",
    "    \"\"\"\n",
    "    Visualize the classification results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Must contain 'classification' and 'confidence' columns\n",
    "    max_c : int\n",
    "        Maximum c value used (for plot title)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create color map\n",
    "    color_map = {\n",
    "        'global': 'red',\n",
    "        'local': 'blue',\n",
    "        'tie': 'purple',\n",
    "        'normal': 'lightgray'\n",
    "    }\n",
    "    \n",
    "    colors = [color_map[c] for c in df['classification']]\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # Plot 1: Classification with consistent colors\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Plot normal points first (background)\n",
    "    normal_mask = df['classification'] == 'normal'\n",
    "    ax1.scatter(df.loc[normal_mask, attr1], \n",
    "                df.loc[normal_mask, attr2],\n",
    "                c='lightgray', s=20, alpha=0.3, label='Normal', zorder=1)\n",
    "    \n",
    "    # Plot classified outliers\n",
    "    for cls, color, label, marker in [\n",
    "        ('global', 'red', 'Global Outlier', 'o'),\n",
    "        ('local', 'blue', 'Local Outlier', '^'),\n",
    "        ('tie', 'purple', 'Tie', 's')\n",
    "    ]:\n",
    "        mask = df['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax1.scatter(df.loc[mask, attr1], \n",
    "                       df.loc[mask, attr2],\n",
    "                       c=color, s=80, alpha=0.8, \n",
    "                       edgecolors='black', linewidth=0.5,\n",
    "                       label=label, marker=marker, zorder=3)\n",
    "    \n",
    "    ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax1.set_title(f'Global vs Local Outlier Classification\\n(Majority Voting, max c={max_c})', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Confidence scores\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Plot normal points\n",
    "    ax2.scatter(df.loc[normal_mask, attr1], \n",
    "                df.loc[normal_mask, attr2],\n",
    "                c='lightgray', s=20, alpha=0.3, label='Normal', zorder=1)\n",
    "    \n",
    "    # Plot classified points with confidence coloring\n",
    "    classified_mask = df['classification'] != 'normal'\n",
    "    if classified_mask.any():\n",
    "        scatter = ax2.scatter(df.loc[classified_mask, attr1], \n",
    "                             df.loc[classified_mask, attr2],\n",
    "                             c=df.loc[classified_mask, 'confidence'],\n",
    "                             cmap='RdYlGn', s=80, alpha=0.8,\n",
    "                             edgecolors='black', linewidth=0.5,\n",
    "                             vmin=0.5, vmax=1.0, zorder=3)\n",
    "        \n",
    "        cbar = plt.colorbar(scatter, ax=ax2)\n",
    "        cbar.set_label('Classification Confidence', fontsize=11)\n",
    "    \n",
    "    ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax2.set_title(f'Classification Confidence Scores\\n(Higher = stronger agreement)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional plot: Vote distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    classified_mask = df['classification'] != 'normal'\n",
    "    if classified_mask.any():\n",
    "        scatter = ax.scatter(df.loc[classified_mask, 'global_votes'], \n",
    "                           df.loc[classified_mask, 'local_votes'],\n",
    "                           c=df.loc[classified_mask, 'classification'].map(color_map),\n",
    "                           s=60, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Add diagonal line (tie line)\n",
    "        max_votes = max(df['global_votes'].max(), df['local_votes'].max())\n",
    "        ax.plot([0, max_votes], [0, max_votes], 'k--', alpha=0.3, linewidth=1, label='Tie line')\n",
    "        \n",
    "        ax.set_xlabel('Global Votes', fontsize=12)\n",
    "        ax.set_ylabel('Local Votes', fontsize=12)\n",
    "        ax.set_title('Vote Distribution', fontsize=13, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add legend manually\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='red', edgecolor='black', label='Global'),\n",
    "            Patch(facecolor='blue', edgecolor='black', label='Local'),\n",
    "            Patch(facecolor='purple', edgecolor='black', label='Tie')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='best', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Functions loaded successfully!\")\n",
    "print(\"\\nUsage example:\")\n",
    "print(\"  c_range = range(10, 101, 5)  # Test c from 10 to 100, step 5\")\n",
    "print(\"  df_classified = majority_vote_classification(df, c_range)\")\n",
    "print(\"  plot_classification_results(df_classified, max_c=100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the majority voting classification\n",
    "\n",
    "c_range = range(5, 51, 5)  \n",
    "\n",
    "df_classified = majority_vote_classification(df, c_range)\n",
    "\n",
    "# Visualize results\n",
    "plot_classification_results(df_classified, max_c=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis: Compare with ground truth and explore different c ranges\n",
    "\n",
    "def analyze_classification_vs_ground_truth(df_classified):\n",
    "    \"\"\"\n",
    "    Analyze how classified outliers relate to ground truth labels.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON WITH GROUND TRUTH\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get ground truth outliers\n",
    "    true_outliers = df_classified[df_classified['is_outlier'] == 1]\n",
    "    true_normals = df_classified[df_classified['is_outlier'] == 0]\n",
    "    \n",
    "    print(f\"\\nGround truth distribution:\")\n",
    "    print(f\"  True outliers: {len(true_outliers)}\")\n",
    "    print(f\"  True normals:  {len(true_normals)}\")\n",
    "    \n",
    "    # Among true outliers, how are they classified?\n",
    "    print(f\"\\nClassification of TRUE OUTLIERS:\")\n",
    "    outlier_classifications = true_outliers['classification'].value_counts()\n",
    "    for cls, count in outlier_classifications.items():\n",
    "        pct = count / len(true_outliers) * 100\n",
    "        print(f\"  {cls:10s}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Among classified global outliers, what % are true outliers?\n",
    "    print(f\"\\nPrecision check:\")\n",
    "    for cls in ['global', 'local']:\n",
    "        classified = df_classified[df_classified['classification'] == cls]\n",
    "        if len(classified) > 0:\n",
    "            true_positive = (classified['is_outlier'] == 1).sum()\n",
    "            precision = true_positive / len(classified) * 100\n",
    "            print(f\"  {cls:10s}: {true_positive}/{len(classified)} are true outliers ({precision:.1f}%)\")\n",
    "    \n",
    "    # Visualize ground truth vs classification\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # Plot 1: Ground truth\n",
    "    ax1 = axes[0]\n",
    "    normal_mask = df_classified['is_outlier'] == 0\n",
    "    outlier_mask = df_classified['is_outlier'] == 1\n",
    "    \n",
    "    ax1.scatter(df_classified.loc[normal_mask, 'attribute_1'], \n",
    "                df_classified.loc[normal_mask, 'attribute_2'],\n",
    "                c='lightgray', s=20, alpha=0.5, label='Normal')\n",
    "    ax1.scatter(df_classified.loc[outlier_mask, 'attribute_1'], \n",
    "                df_classified.loc[outlier_mask, 'attribute_2'],\n",
    "                c='black', s=80, alpha=0.8, marker='x', \n",
    "                edgecolors='red', linewidth=1.5, label='True Outlier')\n",
    "    \n",
    "    ax1.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax1.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax1.set_title('Ground Truth Labels', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Our classification overlaid on ground truth\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Background: ground truth\n",
    "    ax2.scatter(df_classified.loc[normal_mask, 'attribute_1'], \n",
    "                df_classified.loc[normal_mask, 'attribute_2'],\n",
    "                c='lightgray', s=20, alpha=0.3, label='True Normal')\n",
    "    ax2.scatter(df_classified.loc[outlier_mask, 'attribute_1'], \n",
    "                df_classified.loc[outlier_mask, 'attribute_2'],\n",
    "                c='yellow', s=80, alpha=0.5, marker='x', \n",
    "                edgecolors='orange', linewidth=1, label='True Outlier')\n",
    "    \n",
    "    # Overlay: our classification\n",
    "    for cls, color, label, marker in [\n",
    "        ('global', 'red', 'Classified: Global', 'o'),\n",
    "        ('local', 'blue', 'Classified: Local', '^')\n",
    "    ]:\n",
    "        mask = df_classified['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax2.scatter(df_classified.loc[mask, 'attribute_1'], \n",
    "                       df_classified.loc[mask, 'attribute_2'],\n",
    "                       c=color, s=60, alpha=0.7, \n",
    "                       edgecolors='black', linewidth=0.5,\n",
    "                       label=label, marker=marker, zorder=3)\n",
    "    \n",
    "    ax2.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax2.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax2.set_title('Classification Overlaid on Ground Truth', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(loc='best', fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "analyze_classification_vs_ground_truth(df_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed inspection: Show top global and local outliers\n",
    "\n",
    "def inspect_top_outliers(df_classified, n_top=10):\n",
    "    \"\"\"\n",
    "    Display detailed information about the top global and local outliers.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"TOP {n_top} GLOBAL OUTLIERS (sorted by confidence)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    global_outliers = df_classified[df_classified['classification'] == 'global'].copy()\n",
    "    global_outliers = global_outliers.sort_values('confidence', ascending=False).head(n_top)\n",
    "    \n",
    "    cols_to_show = ['attribute_1', 'attribute_2', 'knn_rank', 'lof_rank', \n",
    "                    'global_votes', 'local_votes', 'confidence', 'is_outlier']\n",
    "    print(global_outliers[cols_to_show].to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"TOP {n_top} LOCAL OUTLIERS (sorted by confidence)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    local_outliers = df_classified[df_classified['classification'] == 'local'].copy()\n",
    "    local_outliers = local_outliers.sort_values('confidence', ascending=False).head(n_top)\n",
    "    \n",
    "    print(local_outliers[cols_to_show].to_string())\n",
    "    \n",
    "    # Visualize these specific points\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    \n",
    "    # Background: all points\n",
    "    normal_bg = df_classified['classification'] == 'normal'\n",
    "    ax.scatter(df_classified.loc[normal_bg, 'attribute_1'], \n",
    "              df_classified.loc[normal_bg, 'attribute_2'],\n",
    "              c='lightgray', s=15, alpha=0.2, label='Other points')\n",
    "    \n",
    "    # Top global outliers\n",
    "    ax.scatter(global_outliers['attribute_1'], \n",
    "              global_outliers['attribute_2'],\n",
    "              c='red', s=150, alpha=0.7, marker='o',\n",
    "              edgecolors='darkred', linewidth=2,\n",
    "              label=f'Top {n_top} Global Outliers')\n",
    "    \n",
    "    # Top local outliers\n",
    "    ax.scatter(local_outliers['attribute_1'], \n",
    "              local_outliers['attribute_2'],\n",
    "              c='blue', s=150, alpha=0.7, marker='^',\n",
    "              edgecolors='darkblue', linewidth=2,\n",
    "              label=f'Top {n_top} Local Outliers')\n",
    "    \n",
    "    # Add labels to points\n",
    "    for idx, row in global_outliers.iterrows():\n",
    "        ax.annotate(f\"G{idx}\", \n",
    "                   (row['attribute_1'], row['attribute_2']),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=8, color='darkred', fontweight='bold')\n",
    "    \n",
    "    for idx, row in local_outliers.iterrows():\n",
    "        ax.annotate(f\"L{idx}\", \n",
    "                   (row['attribute_1'], row['attribute_2']),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=8, color='darkblue', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax.set_title(f'Top {n_top} Global vs Local Outliers', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTop global outliers:\")\n",
    "    print(f\"  Avg kNN rank: {global_outliers['knn_rank'].mean():.1f}\")\n",
    "    print(f\"  Avg LOF rank: {global_outliers['lof_rank'].mean():.1f}\")\n",
    "    print(f\"  % true outliers: {(global_outliers['is_outlier'] == 1).sum() / len(global_outliers) * 100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nTop local outliers:\")\n",
    "    print(f\"  Avg kNN rank: {local_outliers['knn_rank'].mean():.1f}\")\n",
    "    print(f\"  Avg LOF rank: {local_outliers['lof_rank'].mean():.1f}\")\n",
    "    print(f\"  % true outliers: {(local_outliers['is_outlier'] == 1).sum() / len(local_outliers) * 100:.1f}%\")\n",
    "\n",
    "\n",
    "# Run inspection\n",
    "inspect_top_outliers(df_classified, n_top=10)\n",
    "\n",
    "# Optional: Save results to CSV\n",
    "# df_classified.to_csv('classified_outliers.csv', index=True)\n",
    "# print(\"\\nResults saved to 'classified_outliers.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test with different k values for kNN and LOF\n",
    "\n",
    "def run_full_pipeline(df_original, k_knn=20, k_lof=20, c_range=range(10, 101, 5)):\n",
    "    \"\"\"\n",
    "    Complete pipeline: run kNN and LOF with specified k values, \n",
    "    then perform majority voting classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : DataFrame\n",
    "        Original dataset with 'attribute_1', 'attribute_2', and 'is_outlier' columns\n",
    "    k_knn : int\n",
    "        Number of neighbors for k-NN\n",
    "    k_lof : int\n",
    "        Number of neighbors for LOF\n",
    "    c_range : range or list\n",
    "        Range of c values for majority voting\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with all scores, ranks, and classifications\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"RUNNING FULL PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"k-NN neighbors: {k_knn}\")\n",
    "    print(f\"LOF neighbors:  {k_lof}\")\n",
    "    print(f\"Voting range:   {list(c_range)[0]} to {list(c_range)[-1]}\")\n",
    "    print()\n",
    "    \n",
    "    df_work = df_original.copy()\n",
    "    X = df_work[['attribute_1', 'attribute_2']].values\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    \n",
    "    # Run k-NN\n",
    "    print(f\"Running k-NN (k={k_knn})...\")\n",
    "    knn_detector = KNN(n_neighbors=k_knn, contamination=0.01)\n",
    "    knn_detector.fit(X_normalized)\n",
    "    knn_scores = knn_detector.decision_scores_\n",
    "    \n",
    "    sorted_indices = np.argsort(knn_scores)[::-1]\n",
    "    knn_ranks = np.empty_like(knn_scores, dtype=int)\n",
    "    knn_ranks[sorted_indices] = np.arange(1, len(knn_scores) + 1)\n",
    "    \n",
    "    df_work['knn_score'] = knn_scores\n",
    "    df_work['knn_rank'] = knn_ranks\n",
    "    \n",
    "    # Run LOF\n",
    "    print(f\"Running LOF (k={k_lof})...\")\n",
    "    lof_detector = LOF(n_neighbors=k_lof, contamination=0.01)\n",
    "    lof_detector.fit(X_normalized)\n",
    "    lof_scores = lof_detector.decision_scores_\n",
    "    \n",
    "    sorted_indices = np.argsort(lof_scores)[::-1]\n",
    "    lof_ranks = np.empty_like(lof_scores, dtype=int)\n",
    "    lof_ranks[sorted_indices] = np.arange(1, len(lof_scores) + 1)\n",
    "    \n",
    "    df_work['lof_score'] = lof_scores\n",
    "    df_work['lof_rank'] = lof_ranks\n",
    "    \n",
    "    # Majority voting classification\n",
    "    print(f\"\\nRunning majority voting...\")\n",
    "    df_result = majority_vote_classification(df_work, c_range)\n",
    "    \n",
    "    print(\"\\nPipeline complete!\")\n",
    "    return df_result\n",
    "\n",
    "\n",
    "# Example: Test with different k values\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING SENSITIVITY TO k VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Small k values (more local)\n",
    "print(\"\\n### Test 1: Small k (k=10) ###\")\n",
    "df_k10 = run_full_pipeline(df, k_knn=10, k_lof=10, c_range=range(10, 101, 5))\n",
    "plot_classification_results(df_k10, max_c=100)\n",
    "\n",
    "# Test 2: Larger k values (more global)\n",
    "print(\"\\n### Test 2: Large k (k=40) ###\")\n",
    "df_k40 = run_full_pipeline(df, k_knn=40, k_lof=40, c_range=range(10, 101, 5))\n",
    "plot_classification_results(df_k40, max_c=100)\n",
    "\n",
    "# Compare the two\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: k=10 vs k=40\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nWith k=10 (more sensitive to local structure):\")\n",
    "print(f\"  Global: {(df_k10['classification'] == 'global').sum()}\")\n",
    "print(f\"  Local:  {(df_k10['classification'] == 'local').sum()}\")\n",
    "\n",
    "print(\"\\nWith k=40 (more global perspective):\")\n",
    "print(f\"  Global: {(df_k40['classification'] == 'global').sum()}\")\n",
    "print(f\"  Local:  {(df_k40['classification'] == 'local').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Export\n",
    "\n",
    "def create_summary_report(df_classified):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary report of the classification results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_points = len(df_classified)\n",
    "    n_global = (df_classified['classification'] == 'global').sum()\n",
    "    n_local = (df_classified['classification'] == 'local').sum()\n",
    "    n_tie = (df_classified['classification'] == 'tie').sum()\n",
    "    n_normal = (df_classified['classification'] == 'normal').sum()\n",
    "    \n",
    "    print(f\"\\n1. OVERALL CLASSIFICATION\")\n",
    "    print(f\"   Total points:     {total_points}\")\n",
    "    print(f\"   Global outliers:  {n_global:4d} ({n_global/total_points*100:5.2f}%)\")\n",
    "    print(f\"   Local outliers:   {n_local:4d} ({n_local/total_points*100:5.2f}%)\")\n",
    "    print(f\"   Ties:             {n_tie:4d} ({n_tie/total_points*100:5.2f}%)\")\n",
    "    print(f\"   Normal points:    {n_normal:4d} ({n_normal/total_points*100:5.2f}%)\")\n",
    "    \n",
    "    # Confidence statistics\n",
    "    classified = df_classified[df_classified['classification'].isin(['global', 'local'])]\n",
    "    if len(classified) > 0:\n",
    "        print(f\"\\n2. CONFIDENCE STATISTICS\")\n",
    "        print(f\"   Mean confidence:  {classified['confidence'].mean():.3f}\")\n",
    "        print(f\"   Median confidence: {classified['confidence'].median():.3f}\")\n",
    "        print(f\"   Std confidence:   {classified['confidence'].std():.3f}\")\n",
    "        print(f\"   High conf (>0.8): {(classified['confidence'] > 0.8).sum()} points\")\n",
    "        print(f\"   Low conf (<0.6):  {(classified['confidence'] < 0.6).sum()} points\")\n",
    "    \n",
    "    # Ground truth comparison\n",
    "    if 'is_outlier' in df_classified.columns:\n",
    "        true_outliers = df_classified[df_classified['is_outlier'] == 1]\n",
    "        \n",
    "        print(f\"\\n3. GROUND TRUTH COMPARISON\")\n",
    "        print(f\"   True outliers in dataset: {len(true_outliers)}\")\n",
    "        print(f\"   Detected by our method:   {n_global + n_local}\")\n",
    "        \n",
    "        # Detection rate\n",
    "        detected = true_outliers['classification'].isin(['global', 'local']).sum()\n",
    "        detection_rate = detected / len(true_outliers) * 100 if len(true_outliers) > 0 else 0\n",
    "        print(f\"   Detection rate:           {detected}/{len(true_outliers)} ({detection_rate:.1f}%)\")\n",
    "        \n",
    "        # Precision\n",
    "        our_outliers = df_classified[df_classified['classification'].isin(['global', 'local'])]\n",
    "        if len(our_outliers) > 0:\n",
    "            true_positives = (our_outliers['is_outlier'] == 1).sum()\n",
    "            precision = true_positives / len(our_outliers) * 100\n",
    "            print(f\"   Precision:                {true_positives}/{len(our_outliers)} ({precision:.1f}%)\")\n",
    "        \n",
    "        # Among detected true outliers, global vs local\n",
    "        detected_outliers = true_outliers[true_outliers['classification'].isin(['global', 'local'])]\n",
    "        if len(detected_outliers) > 0:\n",
    "            n_global_true = (detected_outliers['classification'] == 'global').sum()\n",
    "            n_local_true = (detected_outliers['classification'] == 'local').sum()\n",
    "            print(f\"\\n   Among detected true outliers:\")\n",
    "            print(f\"      Classified as global: {n_global_true} ({n_global_true/len(detected_outliers)*100:.1f}%)\")\n",
    "            print(f\"      Classified as local:  {n_local_true} ({n_local_true/len(detected_outliers)*100:.1f}%)\")\n",
    "    \n",
    "    # Ranking statistics\n",
    "    if 'knn_rank' in df_classified.columns and 'lof_rank' in df_classified.columns:\n",
    "        print(f\"\\n4. RANK STATISTICS\")\n",
    "        \n",
    "        global_outliers = df_classified[df_classified['classification'] == 'global']\n",
    "        local_outliers = df_classified[df_classified['classification'] == 'local']\n",
    "        \n",
    "        if len(global_outliers) > 0:\n",
    "            print(f\"\\n   Global outliers:\")\n",
    "            print(f\"      Avg k-NN rank: {global_outliers['knn_rank'].mean():6.1f}\")\n",
    "            print(f\"      Avg LOF rank:  {global_outliers['lof_rank'].mean():6.1f}\")\n",
    "            print(f\"      Rank ratio:    {(global_outliers['lof_rank'] / global_outliers['knn_rank']).mean():.3f}\")\n",
    "        \n",
    "        if len(local_outliers) > 0:\n",
    "            print(f\"\\n   Local outliers:\")\n",
    "            print(f\"      Avg k-NN rank: {local_outliers['knn_rank'].mean():6.1f}\")\n",
    "            print(f\"      Avg LOF rank:  {local_outliers['lof_rank'].mean():6.1f}\")\n",
    "            print(f\"      Rank ratio:    {(local_outliers['lof_rank'] / local_outliers['knn_rank']).mean():.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "# Generate report for our classification\n",
    "create_summary_report(df_classified)\n",
    "\n",
    "# Optional: Save detailed results\n",
    "save_results = False  # Set to True to save\n",
    "\n",
    "if save_results:\n",
    "    output_file = 'xod_majority_voting_results.csv'\n",
    "    cols_to_save = ['attribute_1', 'attribute_2', 'is_outlier',\n",
    "                    'knn_score', 'knn_rank', 'lof_score', 'lof_rank',\n",
    "                    'global_votes', 'local_votes', 'total_votes',\n",
    "                    'classification', 'confidence']\n",
    "    df_classified[cols_to_save].to_csv(output_file, index=True)\n",
    "    print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "else:\n",
    "    print(f\"\\nTo save results, set save_results = True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Visualization: Rank Difference Analysis\n",
    "\n",
    "def visualize_rank_differences(df_classified):\n",
    "    \"\"\"\n",
    "    Visualize the relationship between k-NN and LOF ranks,\n",
    "    highlighting global vs local outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate rank difference\n",
    "    df_viz = df_classified.copy()\n",
    "    df_viz['rank_diff'] = df_viz['lof_rank'] - df_viz['knn_rank']\n",
    "    df_viz['rank_ratio'] = df_viz['lof_rank'] / (df_viz['knn_rank'] + 1)  # +1 to avoid division by zero\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # Plot 1: k-NN rank vs LOF rank\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    color_map = {'global': 'red', 'local': 'blue', 'tie': 'purple', 'normal': 'lightgray'}\n",
    "    \n",
    "    for cls in ['normal', 'tie', 'local', 'global']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            alpha = 0.2 if cls == 'normal' else 0.7\n",
    "            size = 20 if cls == 'normal' else 60\n",
    "            ax1.scatter(df_viz.loc[mask, 'knn_rank'], \n",
    "                       df_viz.loc[mask, 'lof_rank'],\n",
    "                       c=color_map[cls], s=size, alpha=alpha, \n",
    "                       label=cls.capitalize())\n",
    "    \n",
    "    # Add diagonal line (where kNN rank = LOF rank)\n",
    "    max_rank = max(df_viz['knn_rank'].max(), df_viz['lof_rank'].max())\n",
    "    ax1.plot([0, max_rank], [0, max_rank], 'k--', alpha=0.3, linewidth=1, label='Equal rank')\n",
    "    \n",
    "    ax1.set_xlabel('k-NN Rank', fontsize=12)\n",
    "    ax1.set_ylabel('LOF Rank', fontsize=12)\n",
    "    ax1.set_title('k-NN Rank vs LOF Rank', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='best', fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Rank difference distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    for cls in ['global', 'local']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax2.hist(df_viz.loc[mask, 'rank_diff'], \n",
    "                    bins=30, alpha=0.6, label=cls.capitalize(),\n",
    "                    color=color_map[cls], edgecolor='black')\n",
    "    \n",
    "    ax2.axvline(x=0, color='black', linestyle='--', linewidth=2, alpha=0.5, label='No difference')\n",
    "    ax2.set_xlabel('Rank Difference (LOF - k-NN)', fontsize=12)\n",
    "    ax2.set_ylabel('Count', fontsize=12)\n",
    "    ax2.set_title('Distribution of Rank Differences', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(loc='best', fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: Spatial distribution colored by rank difference\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    classified_mask = df_viz['classification'] != 'normal'\n",
    "    \n",
    "    # Background\n",
    "    ax3.scatter(df_viz.loc[~classified_mask, 'attribute_1'],\n",
    "               df_viz.loc[~classified_mask, 'attribute_2'],\n",
    "               c='lightgray', s=20, alpha=0.3, label='Normal')\n",
    "    \n",
    "    # Classified points\n",
    "    scatter = ax3.scatter(df_viz.loc[classified_mask, 'attribute_1'],\n",
    "                         df_viz.loc[classified_mask, 'attribute_2'],\n",
    "                         c=df_viz.loc[classified_mask, 'rank_diff'],\n",
    "                         cmap='RdBu_r', s=80, alpha=0.8,\n",
    "                         edgecolors='black', linewidth=0.5,\n",
    "                         vmin=-100, vmax=100)\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, ax=ax3)\n",
    "    cbar.set_label('Rank Difference (LOF - k-NN)', fontsize=11)\n",
    "    \n",
    "    ax3.set_xlabel('Attribute 1', fontsize=12)\n",
    "    ax3.set_ylabel('Attribute 2', fontsize=12)\n",
    "    ax3.set_title('Points colored by Rank Difference\\n(Red: LOF>k-NN, Blue: k-NN>LOF)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Confidence vs rank statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    for cls in ['global', 'local']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            ax4.scatter(df_viz.loc[mask, 'confidence'],\n",
    "                       df_viz.loc[mask, 'rank_diff'],\n",
    "                       c=color_map[cls], s=60, alpha=0.6,\n",
    "                       label=cls.capitalize(), edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax4.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax4.set_xlabel('Classification Confidence', fontsize=12)\n",
    "    ax4.set_ylabel('Rank Difference (LOF - k-NN)', fontsize=12)\n",
    "    ax4.set_title('Confidence vs Rank Difference', fontsize=13, fontweight='bold')\n",
    "    ax4.legend(loc='best', fontsize=10)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"=\"*70)\n",
    "    print(\"RANK DIFFERENCE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for cls in ['global', 'local']:\n",
    "        mask = df_viz['classification'] == cls\n",
    "        if mask.any():\n",
    "            print(f\"\\n{cls.upper()} outliers:\")\n",
    "            print(f\"  Mean rank difference: {df_viz.loc[mask, 'rank_diff'].mean():7.1f}\")\n",
    "            print(f\"  Median rank diff:     {df_viz.loc[mask, 'rank_diff'].median():7.1f}\")\n",
    "            print(f\"  Std rank diff:        {df_viz.loc[mask, 'rank_diff'].std():7.1f}\")\n",
    "            \n",
    "            # Count how many have LOF rank better than kNN rank\n",
    "            better_lof = (df_viz.loc[mask, 'rank_diff'] < 0).sum()\n",
    "            better_knn = (df_viz.loc[mask, 'rank_diff'] > 0).sum()\n",
    "            print(f\"  LOF rank < k-NN rank: {better_lof}\")\n",
    "            print(f\"  LOF rank > k-NN rank: {better_knn}\")\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "visualize_rank_differences(df_classified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastLOF Env",
   "language": "python",
   "name": "fastlof-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
